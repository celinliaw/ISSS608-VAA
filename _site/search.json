[
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "For this take-home exercise 2, Mini-Challenge 3 will be chosen and the visualisation will be done on this topic. The background of the mini challenge and the questions will be listed below. For this mini challenge, I will only be displaying and addressing Question 3 below."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#getting-started",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#getting-started",
    "title": "Take-Home_Ex02",
    "section": "Getting Started",
    "text": "Getting Started\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\n\nCode\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph,\n               SmartEDA)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#import-knowledge-graph-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#import-knowledge-graph-data",
    "title": "Take-Home_Ex02",
    "section": "Import knowledge Graph Data",
    "text": "Import knowledge Graph Data\nFor this exercise, mc3.json file will be used. In the code chunk below, fromJSON() of jsonlite package is used to import mc3.json file into R and save the output object.\n\n\nCode\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#inspecting-knowledge-graph-structure",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#inspecting-knowledge-graph-structure",
    "title": "Take-Home_Ex02",
    "section": "Inspecting Knowledge graph structure",
    "text": "Inspecting Knowledge graph structure\nIn the code chunk below, glimpse() is used to reveal the structure of the mc3 knowledge graph.\n\n\nCode\nglimpse(MC3)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ..."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-Home_Ex02",
    "section": "Extracting the edges and nodes tables",
    "text": "Extracting the edges and nodes tables\nNext, as_tibble() of tibble package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes and mc3_edges respectively.\n\n\nCode\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#initial-eda",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#initial-eda",
    "title": "Take-Home_Ex02",
    "section": "Initial EDA",
    "text": "Initial EDA\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in mc3_nodes tibble dataframe\n\n\nCode\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\nOn the other hand, code chunk below uses ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in mc3_edges tibble dataframe\n\n\nCode\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n\n[[1]]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#data-cleaning-and-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#data-cleaning-and-wrangling",
    "title": "Take-Home_Ex02",
    "section": "Data Cleaning and Wrangling",
    "text": "Data Cleaning and Wrangling\nThe code chunk below performs the following data cleaning tasks:\n\nconvert values in id field into character data type\nexclude records with id value\nexclude records with similar id values\nexclude thing_collected field\nsave the cleaned tibble dataframe into a new tibble datatable called mc_nodes_cleaned\n\n\n\nCode\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#cleaning-and-wrangling-edges",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02P1.html#cleaning-and-wrangling-edges",
    "title": "Take-Home_Ex02",
    "section": "Cleaning and wrangling edges",
    "text": "Cleaning and wrangling edges\nNext, the code chunk will be used to:\n\nrename source and target fields to form_id and to_id respectively\nconvert values in from_id and to_id fields to character data type\nexclude values in from_id and to_id which is not found in the id field of mc3_nodes_cleaned\nexclude records whereby from_id and/or to_id values are missing\nsave the cleaned tibble dataframe and call it mc3_edges_cleaned\n\n\n\nCode\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source,\n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id),\n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id,\n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index.\n\n\nCode\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below will be used to join and convert from_id and to_id to integer indices. At the same time, we will drop rows with unmatched nodes.\n\n\nCode\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to))  \n\n\nNext, the code chunk below is used to subset nodes to only those referenced by edges\n\n\nCode\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe will then use th code chunk below to rebuild lookup from old index to new index\n\n\nCode\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table\n\n\nCode\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\nCode\nglimpse(mc3_edges_final)\n\n\nRows: 3,226\nColumns: 4\n$ from        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ to          &lt;int&gt; 1138, 357, 747, 895, 876, 888, 896, 145, 404, 876, 888, 92…\n$ is_inferred &lt;lgl&gt; TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, T…\n$ type        &lt;chr&gt; NA, \"sent\", NA, NA, NA, NA, NA, \"sent\", \"sent\", NA, NA, NA…"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html",
    "title": "Take-Home Exercise 1 Part 2",
    "section": "",
    "text": "For part 2 of the Take-Home Exercise 1, I will be evaluating one of my peer’s Ng Wee Tinn Shermainn’s website for her Take-Home Exercise 1. I will be providing 3 good design principles and 3 areas for further improvements for the data visualisation plots done by Shermainn"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#top-10-subzones-of-each-age-group",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#top-10-subzones-of-each-age-group",
    "title": "Take-Home Exercise 1 Part 2",
    "section": "2.1 Top 10 subzones of each age group",
    "text": "2.1 Top 10 subzones of each age group\n3 Good Design Principles:\n\nAnalysis is split into the different population age groups which makes it easier to analyse the graphs based on the age groups\nThe analysis identifies the top 10 subzones for each age group and makes it easier to identify the facilities that are required for each subzone based on age group\nThe graphs are ordered in descending order according to their population (from the largest population to the 10th largest population), making it easier for viewing based on the position of the bar graph, making it easy to identify which subzone has the largest population\n\n3 Areas for Further Improvements:\n\nThe colours for the bar charts are in shades of grey which makes it hard to differentiate the different subzones. It would be better if specific colours are used for each area. In the code below, I will be adding colours to the graphs to make it easy to differentiate between the different subzones.\nThere are many tabs in one page and it may be hard to do comparisons. It would be better to make them all in 1 page so that comparisons can be done easily. The code #| code-fold: true is added so that the codes can be hidden and only the graphs are shown for easier comparisons.\nThe chart also only shows the top 10 subzones but the other subzones were not shown. It would be better if the lowest 10 subzones or all subzones can be shown. In the makeover below, I will be adding the top and bottom 10 subzones for easy reference.\n\nI have added screenshots of her website visualisations below for easy reference:"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#data-wrangling",
    "title": "Take-Home Exercise 1 Part 2",
    "section": "2.2 Data Wrangling",
    "text": "2.2 Data Wrangling\n\n2.2.1 Load Packages\n\n\nCode\npacman::p_load(tidyverse,patchwork, ggthemes, dplyr)\n\n\n\n\n2.2.2 Import Data\n\n\nCode\npopdata &lt;- read_csv(\"respopagesex2024.csv\")\n\n\n\n\n2.2.3 Categorizing into Main zones and Subzones\n\n\nCode\n# Clean and process the data\npopdata_cleaned &lt;- popdata %&gt;%\n  rename(\n    Planning_Area = PA,\n    Subzone = SZ,\n    Population = Pop\n  ) %&gt;%\n  filter(Sex != \"Total\", Age != \"Total\", Subzone != \"Total\") %&gt;%\n  mutate(\n    Population = as.numeric(Population),\n    Age = as.numeric(Age),\n    Age_Group = case_when(\n      Age &gt;= 0 & Age &lt;= 4 ~ \"Young (0-4)\",\n      Age &gt;= 5 & Age &lt;= 12 ~ \"Youth (5-12)\",\n      Age &gt;= 13 & Age &lt;= 17 ~ \"Teens (13-17)\",\n      Age &gt;= 18 & Age &lt;= 64 ~ \"Working Adults (18-64)\",\n      Age &gt;= 65 ~ \"Elderly (65+)\",\n      TRUE ~ NA_character_\n    )\n  ) %&gt;%\n  filter(!is.na(Age_Group)) %&gt;%\n  group_by(Planning_Area, Subzone, Age_Group) %&gt;%\n  summarise(Total_Population = sum(Population, na.rm = TRUE), .groups = \"drop\")\n\n# View results\nhead(popdata_cleaned)\n\n\n# A tibble: 6 × 4\n  Planning_Area Subzone                Age_Group              Total_Population\n  &lt;chr&gt;         &lt;chr&gt;                  &lt;chr&gt;                             &lt;dbl&gt;\n1 Ang Mo Kio    Ang Mo Kio Town Centre Elderly (65+)                       880\n2 Ang Mo Kio    Ang Mo Kio Town Centre Teens (13-17)                       290\n3 Ang Mo Kio    Ang Mo Kio Town Centre Working Adults (18-64)             3170\n4 Ang Mo Kio    Ang Mo Kio Town Centre Young (0-4)                         120\n5 Ang Mo Kio    Ang Mo Kio Town Centre Youth (5-12)                        420\n6 Ang Mo Kio    Cheng San              Elderly (65+)                      6580\n\n\n\n\n2.2.4 Top 10 and Bottom 10 Subzones of each age group\nIn this code, i have added colours to the different Subzones and also put the top 10 and bottom 10 subzones side-by-side to make it more easier to compare.\nThe code #| code-fold: true is also added at the top of the codes to make sure the codes are collapsible and the other graphs can be easily comparable after collapsing the codes. They have also been displayed from the youngest to the oldest.\nTop 10 vs Bottom 10 Subzones of Young Population (0-4 Years Old)\n\n\nCode\n# Load necessary libraries\npacman::p_load(tidyverse, patchwork, RColorBrewer)\n\n# Get top 10 and bottom 10 subzones of young population\ntop_young_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Young (0-4)\") %&gt;%\n  arrange(desc(Total_Population)) %&gt;%\n  slice_head(n = 10)\n\nbottom_young_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Young (0-4)\", Total_Population &gt; 0) %&gt;%\n  arrange(Total_Population) %&gt;%\n  slice_head(n = 10)\n\n# SAFE color assignment for top and bottom (brewer.pal only works up to 12 for Set3 and 8 for Pastel2)\ntop_n &lt;- nrow(top_young_subzones)\nbottom_n &lt;- nrow(bottom_young_subzones)\n\ntop_palette &lt;- brewer.pal(max(3, min(top_n, 12)), \"Set3\")\nbottom_palette &lt;- brewer.pal(max(3, min(bottom_n, 8)), \"Pastel2\")\n\ntop_colors &lt;- setNames(top_palette[1:top_n], top_young_subzones$Subzone)\nbottom_colors &lt;- setNames(bottom_palette[1:bottom_n], bottom_young_subzones$Subzone)\n\n# Plot: Top 10\ny1 &lt;- ggplot(top_young_subzones, \n             aes(x = reorder(Subzone, Total_Population), \n                 y = Total_Population, \n                 fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Subzones\\n of Young Population\",\n    x = \"Subzone\",\n    y = \"Number of Young Residents\"\n  ) +\n  scale_fill_manual(values = top_colors) +\n  scale_y_continuous(\n    breaks = seq(0, max(top_young_subzones$Total_Population), by = 1000),\n    labels = function(x) paste0(x / 1000, \"K\"),\n    limits = c(0, max(top_young_subzones$Total_Population) + 1000),\n    expand = c(0, 0)\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Plot: Bottom 10\ny2 &lt;- ggplot(bottom_young_subzones, \n             aes(x = reorder(Subzone, Total_Population), \n                 y = Total_Population, \n                 fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Bottom 10 Subzones\\n of Young Population\",\n    x = \"Subzone\",\n    y = \"Number of Young Residents\"\n  ) +\n  scale_fill_manual(values = bottom_colors) +\n  scale_y_continuous(\n    limits = c(0, max(bottom_young_subzones$Total_Population) + 50),\n    labels = function(x) ifelse(x &gt;= 1000, paste0(x / 1000, \"K\"), x),\n    expand = c(0, 0)\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Combine the plots side by side\ny1 + y2 +\n  plot_layout(ncol = 2) +\n  plot_annotation(\n    title = \"Comparison of Young Population (0–4YO)\\n Across Singapore Subzones\",\n    subtitle = \"Top 10 vs Bottom 10 Subzones of Youngest Residents\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n      plot.subtitle = element_text(hjust = 0.5, size = 12)\n    )\n  )\n\n\n\n\n\n\n\n\n\nTop 10 vs Bottom 10 Subzones of Youths (5-12 Years Old)\n\n\nCode\n# Load required packages\npacman::p_load(tidyverse, patchwork, RColorBrewer)\n\n# Get top 10 and bottom 10 subzones of youth population\ntop_youth_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Youth (5-12)\") %&gt;%\n  arrange(desc(Total_Population)) %&gt;%\n  slice_head(n = 10)\n\nbottom_youth_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Youth (5-12)\", Total_Population &gt; 0) %&gt;%\n  arrange(Total_Population) %&gt;%\n  slice_head(n = 10)\n\n# Safely assign palette colors\ntop_n &lt;- nrow(top_youth_subzones)\nbottom_n &lt;- nrow(bottom_youth_subzones)\n\ntop_palette &lt;- brewer.pal(max(3, min(top_n, 12)), \"Set3\")\nbottom_palette &lt;- brewer.pal(max(3, min(bottom_n, 8)), \"Pastel2\")\n\ntop_colors &lt;- setNames(top_palette[1:top_n], top_youth_subzones$Subzone)\nbottom_colors &lt;- setNames(bottom_palette[1:bottom_n], bottom_youth_subzones$Subzone)\n\n# Plot: Top 10\ny_top &lt;- ggplot(top_youth_subzones, \n                aes(x = reorder(Subzone, Total_Population), \n                    y = Total_Population, \n                    fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Subzones of\\n Youth Population\",\n    x = \"Subzone\",\n    y = \"Number of Youth Residents\"\n  ) +\n  scale_fill_manual(values = top_colors) +\n  scale_y_continuous(\n    breaks = seq(0, 10000, by = 2000),\n    labels = function(x) paste0(x / 1000, \"K\"),\n    limits = c(0, max(top_youth_subzones$Total_Population) + 2000),\n    expand = c(0, 0)\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Plot: Bottom 10\ny_bottom &lt;- ggplot(bottom_youth_subzones, \n                   aes(x = reorder(Subzone, Total_Population), \n                       y = Total_Population, \n                       fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Bottom 10 Subzones of\\n Youth Population\",\n    x = \"Subzone\",\n    y = \"Number of Youth Residents\"\n  ) +\n  scale_fill_manual(values = bottom_colors) +\n  scale_y_continuous(\n    limits = c(0, max(bottom_youth_subzones$Total_Population) + 50),\n    labels = function(x) ifelse(x &gt;= 1000, paste0(x / 1000, \"K\"), x),\n    expand = c(0, 0)\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Combine both plots side by side\ny_top + y_bottom +\n  plot_layout(ncol = 2) +\n  plot_annotation(\n    title = \"Comparison of Youth Population (5–12YO)\\n Across Singapore Subzones\",\n    subtitle = \"Top 10 vs Bottom 10 Subzones of Youth Residents\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n      plot.subtitle = element_text(hjust = 0.5, size = 12)\n    )\n  )\n\n\n\n\n\n\n\n\n\nTop 10 vs Bottom 10 Subzones of Teens (13-17 Years Old)\n\n\nCode\n# Load required packages\npacman::p_load(tidyverse, patchwork, RColorBrewer)\n\n# Get top 10 and bottom 10 subzones by teen population\ntop_teen_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Teens (13-17)\") %&gt;%\n  arrange(desc(Total_Population)) %&gt;%\n  slice_head(n = 10)\n\nbottom_teen_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Teens (13-17)\", Total_Population &gt; 0) %&gt;%\n  arrange(Total_Population) %&gt;%\n  slice_head(n = 10)\n\n# Color-safe assignment\ntop_n &lt;- nrow(top_teen_subzones)\nbottom_n &lt;- nrow(bottom_teen_subzones)\n\ntop_palette &lt;- brewer.pal(max(3, min(top_n, 12)), \"Set3\")\nbottom_palette &lt;- brewer.pal(max(3, min(bottom_n, 8)), \"Pastel2\")\n\ntop_colors &lt;- setNames(top_palette[1:top_n], top_teen_subzones$Subzone)\nbottom_colors &lt;- setNames(bottom_palette[1:bottom_n], bottom_teen_subzones$Subzone)\n\n# Plot: Top 10\nt_top &lt;- ggplot(top_teen_subzones, \n                aes(x = reorder(Subzone, Total_Population), \n                    y = Total_Population, \n                    fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Subzones of\\n Teen Population\",\n    x = \"Subzone\",\n    y = \"Number of Teen Residents\"\n  ) +\n  scale_fill_manual(values = top_colors) +\n  scale_y_continuous(\n    breaks = seq(0, 6000, by = 1000),\n    labels = function(x) paste0(x / 1000, \"K\"),\n    limits = c(0, max(top_teen_subzones$Total_Population) + 1000),\n    expand = c(0, 0)\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Plot: Bottom 10\nt_bottom &lt;- ggplot(bottom_teen_subzones, \n                   aes(x = reorder(Subzone, Total_Population), \n                       y = Total_Population, \n                       fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Bottom 10 Subzones of\\n Teen Population\",\n    x = \"Subzone\",\n    y = \"Number of Teen Residents\"\n  ) +\n  scale_fill_manual(values = bottom_colors) +\n  scale_y_continuous(\n    limits = c(0, max(bottom_teen_subzones$Total_Population) + 50),\n    labels = function(x) ifelse(x &gt;= 1000, paste0(x / 1000, \"K\"), x),\n    expand = c(0, 0)\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Combine both plots side by side\nt_top + t_bottom +\n  plot_layout(ncol = 2) +\n  plot_annotation(\n    title = \"Comparison of Teen Population (13–17YO)\\n Across Singapore Subzones\",\n    subtitle = \"Top 10 vs Bottom 10 Subzones of Teen Residents\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n      plot.subtitle = element_text(hjust = 0.5, size = 12)\n    )\n  )\n\n\n\n\n\n\n\n\n\nTop 10 vs Bottom 10 Subzones of Working Adults (18-64 Years Old)\n\n\nCode\n# Load required packages\npacman::p_load(tidyverse, patchwork, RColorBrewer, scales)\n\n# Get top 10 and bottom 10 subzones by working adults population\ntop_working_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Working Adults (18-64)\") %&gt;%\n  arrange(desc(Total_Population)) %&gt;%\n  slice_head(n = 10)\n\nbottom_working_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Working Adults (18-64)\", Total_Population &gt; 0) %&gt;%\n  arrange(Total_Population) %&gt;%\n  slice_head(n = 10)\n\n# Safely assign colors based on count\ntop_n &lt;- nrow(top_working_subzones)\nbottom_n &lt;- nrow(bottom_working_subzones)\n\ntop_palette &lt;- brewer.pal(max(3, min(top_n, 12)), \"Set3\")\nbottom_palette &lt;- brewer.pal(max(3, min(bottom_n, 8)), \"Pastel2\")\n\ntop_colors &lt;- setNames(top_palette[1:top_n], top_working_subzones$Subzone)\nbottom_colors &lt;- setNames(bottom_palette[1:bottom_n], bottom_working_subzones$Subzone)\n\n# Plot: Top 10\na_top &lt;- ggplot(top_working_subzones, \n                aes(x = reorder(Subzone, Total_Population), \n                    y = Total_Population, \n                    fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = comma(Total_Population)), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Subzones of\\nWorking Adult Population\",\n    x = \"Subzone\",\n    y = \"Number of Working Adults\"\n  ) +\n  scale_fill_manual(values = top_colors) +\n  scale_y_continuous(\n  breaks = seq(0, 100000, by = 20000),\n  limits = c(0, 110000 + 5000),\n  expand = c(0, 0),\n  labels = function(x) paste0(x / 1000, \"K\")\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Plot: Bottom 10\na_bottom &lt;- ggplot(bottom_working_subzones, \n                   aes(x = reorder(Subzone, Total_Population), \n                       y = Total_Population, \n                       fill = Subzone)) +\n  geom_col() +\n  geom_text(aes(label = comma(Total_Population)), \n            hjust = -0.1, size = 3.5, color = \"black\") +  # adjusted label position\n  coord_flip() +\n  labs(\n    title = \"Bottom 10 Subzones of\\nWorking Adult Population\",\n    x = \"Subzone\",\n    y = \"Number of Working Adults\"\n  ) +\n  scale_fill_manual(values = bottom_colors) +\n  scale_y_continuous(\n    limits = c(0, max(bottom_working_subzones$Total_Population) + 500),\n    expand = c(0, 0),\n    labels = comma\n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Combine both plots side by side\na_top + a_bottom +\n  plot_layout(ncol = 2) +\n  plot_annotation(\n    title = \"Comparison of Working Adult Population (18–64YO)\\nAcross Singapore Subzones\",\n    subtitle = \"Top 10 vs Bottom 10 Subzones of Working Adults Residents\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n      plot.subtitle = element_text(hjust = 0.5, size = 12)\n    )\n  )\n\n\n\n\n\n\n\n\n\nTop 10 vs Bottom 10 Subzones of Elderly Population (65+ Years Old)\n\n\nCode\ntop_elderly_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Elderly (65+)\") %&gt;%\n  arrange(desc(Total_Population)) %&gt;%\n  slice_head(n = 10)\n\n# Load required libraries\npacman::p_load(tidyverse, patchwork, ggthemes, RColorBrewer)\n\n# Load the data\npopdata &lt;- read_csv(\"respopagesex2024.csv\")\n\n# Clean and process the data\npopdata_cleaned &lt;- popdata %&gt;%\n  rename(\n    Planning_Area = PA,\n    Subzone = SZ,\n    Population = Pop\n  ) %&gt;%\n  filter(Sex != \"Total\", Age != \"Total\", Subzone != \"Total\") %&gt;%\n  mutate(\n    Population = as.numeric(Population),\n    Age = as.numeric(Age),\n    Age_Group = case_when(\n      Age &gt;= 0 & Age &lt;= 4 ~ \"Young (0-4)\",\n      Age &gt;= 5 & Age &lt;= 12 ~ \"Youth (5-12)\",\n      Age &gt;= 13 & Age &lt;= 17 ~ \"Teens (13-17)\",\n      Age &gt;= 18 & Age &lt;= 64 ~ \"Working Adults (18-64)\",\n      Age &gt;= 65 ~ \"Elderly (65+)\",\n      TRUE ~ NA_character_\n    )\n  ) %&gt;%\n  filter(!is.na(Age_Group)) %&gt;%\n  group_by(Planning_Area, Subzone, Age_Group) %&gt;%\n  summarise(Total_Population = sum(Population, na.rm = TRUE), .groups = \"drop\")\n\n# Top 10 subzones by elderly population\ntop_elderly_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Elderly (65+)\") %&gt;%\n  arrange(desc(Total_Population)) %&gt;%\n  slice_head(n = 10)\n\n# Bottom 10 subzones (filter out 0s)\nbottom_elderly_subzones &lt;- popdata_cleaned %&gt;%\n  filter(Age_Group == \"Elderly (65+)\", Total_Population &gt; 0) %&gt;%\n  arrange(Total_Population) %&gt;%\n  slice_head(n = 10)\n\n# Plot: Top 10\ne1 &lt;- ggplot(top_elderly_subzones, \n             aes(x = reorder(Subzone, Total_Population), \n                 y = Total_Population, \n                 fill = Subzone)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +  # Move label inside\n  labs(\n    title = \"Top 10 Subzones\\n by Elderly Population\",\n    x = \"Subzone\",\n    y = \"Elderly Population\"\n  ) +\n  scale_fill_brewer(palette = \"Set3\") +\n  scale_x_discrete(expand = expansion(mult = c(0.05, 0.05))) +\n  # scale_y_continuous(\n  #   breaks = seq(0, 25000, by = 5000),  # Cleaner axis ticks\n  #   limits = c(0, max(top_elderly_subzones$Total_Population) + 2000),  \n  #   expand = c(0, 0)  \n  # ) +\n  scale_y_continuous(\n  breaks = seq(0, 25000, by = 5000),  # Tick marks at 5K intervals\n  limits = c(0, max(top_elderly_subzones$Total_Population) + 2000),\n  labels = function(x) paste0(x / 1000, \"K\"),\n  expand = c(0, 0)\n  ) +\n\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Plot: Bottom 10\ne2 &lt;- ggplot(bottom_elderly_subzones, \n             aes(x = reorder(Subzone, Total_Population), \n                 y = Total_Population, \n                 fill = Subzone)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = Total_Population), \n            hjust = 1.05, size = 3.5, color = \"black\") +\n  labs(\n    title = \"Bottom 10 Subzones\\n by Elderly Population\",\n    x = \"Subzone\",\n    y = \"Elderly Population\"\n  ) +\n  scale_fill_brewer(palette = \"Set3\") +\n  scale_x_discrete(expand = expansion(mult = c(0.05, 0.05))) +\n  scale_y_continuous(\n    limits = c(0, max(bottom_elderly_subzones$Total_Population) + 20),  \n    expand = c(0, 0)  \n  ) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text = element_text(size = 10)\n  )\n\n# Combine plots side by side\ne1 + e2 + \n  plot_layout(ncol = 2) + \n  plot_annotation(\n    title = \"Comparison of Elderly Population(65+ YO)\\n Across Singapore Subzones\",\n    subtitle = \"Top 10 vs Bottom 10 Subzones of Elderly Residents (Age 65+)\",\n    theme = theme(\n      plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n      plot.subtitle = element_text(hjust = 0.5, size = 12)\n    )\n  )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Celin’s ISSS608",
    "section": "",
    "text": "Welcome to ISSS609 Visual Analytics and Applications homepage.\nIn this website, you will find my coursework prepared for this course.\n😸 🐾 🐈‍⬛"
  },
  {
    "objectID": "In-Class _Ex/In-Class_Ex05/In-Class_Ex05.html",
    "href": "In-Class _Ex/In-Class_Ex05/In-Class_Ex05.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "In this code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\n\nCode\npacman::p_load(tidyverse,jsonlite, \n               SmartEDA, tidygraph, \n               ggraph)\n\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC_1graph.json from into R and sae the output object\n\n\nCode\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\n\n\nCode\nstr(kg, max.level = 1)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\nTo do some data cleaning, we separate out into nodes_tb1 and edges_tb1 from the json file.\n\n\nCode\nnodes_tb1 &lt;- as_tibble(kg$nodes)\nedges_tb1 &lt;- as_tibble(kg$links)\n\n\n\n\n\n\n\nCode\nggplot(data = edges_tb1, \n       aes(y = `Edge Type`)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = nodes_tb1, \n       aes(y = `Node Type`)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nid_map &lt;- tibble(id = nodes_tb1$id,\n                 index = seq_len(nrow(nodes_tb1)))\n\n\nThis ensures each id from your node list is mapped to the correct row number.\n\n\n\n\n\nCode\nedges_tb1 &lt;- edges_tb1 %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\n\n\n\n\n\n\nCode\nedges_tb1 &lt;- edges_tb1 %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\n\n\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\n\nCode\ngraph &lt;- tbl_graph(nodes = nodes_tb1,\n                   edges = edges_tb1, \n                   directed = kg$directed)\n\n\n\n\n\n\n\nCode\nset.seed(1234) #ensures to get back the same graph\n\n\n\n\n\n\n\nCode\nggraph(graph, layout = \"fr\") +\n  geom_edge_link(alpha = 0.3,\n                 colour = \"gray\") +\n  geom_node_point(aes(colour = `Node Type`),\n                  size = 4) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nCode\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\n\n\n\n\nCode\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\n\n\n\n\nCode\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id) #optional clean up\n\n\n\n\n\n\n\nCode\nggraph(graph_memberof, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(colour = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "In-Class _Ex/In-Class_Ex05/In-Class_Ex05.html#create-knowledge-graph",
    "href": "In-Class _Ex/In-Class_Ex05/In-Class_Ex05.html#create-knowledge-graph",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "Code\nid_map &lt;- tibble(id = nodes_tb1$id,\n                 index = seq_len(nrow(nodes_tb1)))\n\n\nThis ensures each id from your node list is mapped to the correct row number.\n\n\n\n\n\nCode\nedges_tb1 &lt;- edges_tb1 %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\n\n\n\n\n\n\nCode\nedges_tb1 &lt;- edges_tb1 %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\n\n\nLastly, tbl_graph() is used to create tidygraph’s graph object by using the code chunk below.\n\n\nCode\ngraph &lt;- tbl_graph(nodes = nodes_tb1,\n                   edges = edges_tb1, \n                   directed = kg$directed)\n\n\n\n\n\n\n\nCode\nset.seed(1234) #ensures to get back the same graph\n\n\n\n\n\n\n\nCode\nggraph(graph, layout = \"fr\") +\n  geom_edge_link(alpha = 0.3,\n                 colour = \"gray\") +\n  geom_node_point(aes(colour = `Node Type`),\n                  size = 4) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nCode\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\n\n\n\n\nCode\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\n\n\n\n\nCode\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id) #optional clean up\n\n\n\n\n\n\n\nCode\nggraph(graph_memberof, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(colour = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "In-Class _Ex/In-Class_Ex03/In-Class_Ex03.html",
    "href": "In-Class _Ex/In-Class_Ex03/In-Class_Ex03.html",
    "title": "In-Class Exercise 03",
    "section": "",
    "text": "Tableau Exercise - Using superstore 2020 data from lesson 2\nCreating a sales vs profit graph\n\nDrag Profit to rows and Sales to Columns\nDrag State to detail under Marks\nDrag Sales to Size to adjust the size of the bubble\nDrag Profit to Color to adjust the colour of the bubbles\nDrag Order Date to filters to filter based on the year of the profit - Click on the dropdown\n\nCreating\n\nDrag sales to Rows and Order date to column\nTo create a dual axis graph, drag Profit to the graph until you see the dotted horizontal line and drop it"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#learning-outcome",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "12.1 Learning outcome",
    "text": "12.1 Learning outcome\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#the-data",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "15.1 The data",
    "text": "15.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#data-import-and-preparation",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "25.2 Data Import and Preparation",
    "text": "25.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\n\nCode\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\n\nCode\nlist(sgpools)\n\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "25.3 Creating a sf data frame from an aspatial data frame",
    "text": "25.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\n\nCode\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\n\nCode\nlist(sgpools_sf)\n\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "16.1 It all started with an interactive point symbol map",
    "text": "16.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n           size = 1,\n           col = \"black\",\n           lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "16.2 Lets make it proportional",
    "text": "16.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "16.3 Lets give it a different colour",
    "text": "16.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#i-have-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#i-have-twin-brothers",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "16.4 I have twin brothers",
    "text": "16.4 I have twin brothers\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\n\nCode\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#all-about-tmap-package",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "17.1 All about tmap package",
    "text": "17.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "17.2 Geospatial data wrangling",
    "text": "17.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#data-wrangling",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "27.3 Data wrangling",
    "text": "27.3 Data wrangling"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "Celin's ISSS608 Site",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of this hands-on exercise, the following data visualisation should be created using R packages:\n\nplotting a calendar heatmap by using ggplot2 functions\nplotting a cycle plot using ggplot2 function\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggtheme, gridExtra, readxl, knitr, data.table and tidyverse\n\n\nCode\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nBy the end of of this section, the following will be achieved:\n\nplot a calendar heatmap by using ggplot2 functions and extension\nto write function using R programming\nto derive specific data and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country,\n\n\n\nFirst, I will use the coded chunk below to import eventlog.csv file into R environment and the data frame will be named as attacks.\n\n\nCode\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\n\nThis function kable() can be used to review the structure of the imported data frame.\n\n\nCode\nkable(head(attacks))\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores data-time values in POSIXct format\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code\ntz field stores time zone of the source IP address\n\n\n\n\nStep 1: Deriving weekday and hour of days fields\nBefore we plot the calendar heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\n\nCode\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from {lubridate} package, and\n\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\n\nCode\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n\nNote\n\n\n\nBesides extracting the necessary data into attacks data frame, mutate() of dpylr package is used to convert wkday and hours fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble after processing.\n\n\nCode\nkable(head(attacks))\n\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\nCode\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") +\ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the Code Chunk\n\n\n\n\nA tibble data table called grouped is derived by aggregating the attack by wkday and hour fields\nA new field called n is derived by using group_by() and count() functions\nna.omit() is used to exclude missing value\ngeom_tile() is used to plot tiles (grids) at each x and y position\ncolor and size arguments are used to specify the border color and line size of the tiles\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components fo the default ggplot2 have been excluded, this line can be commented out to examine the default plot\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1\nscale_fill_gradient() function is used to create a two colour gradient (low-high)\n\n\n\nThe count is then grouped by hour and wkday and plotted. Since there are values for every combination, there is no need to further preprocess the data.\n\n\n\nTo build multiple heatmaps for the top 4 countries with the highest number of attacks.\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the following:\n\ncount the number of attacjs by country\ncalculate the percent of attacks by country\nsave the results in a tibble data frame\n\n\n\nCode\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2: Preparing the tidy data fram\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\n\nCode\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\n\nStep 3: Plotting Multiple Calendar Heatmap by using ggplot2 package\n\n\nCode\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of this hands-on exercise, the following data visualisation should be created using R packages:\n\nplotting a calendar heatmap by using ggplot2 functions\nplotting a cycle plot using ggplot2 function\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggtheme, gridExtra, readxl, knitr, data.table and tidyverse\n\n\nCode\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of of this section, the following will be achieved:\n\nplot a calendar heatmap by using ggplot2 functions and extension\nto write function using R programming\nto derive specific data and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country,\n\n\n\nFirst, I will use the coded chunk below to import eventlog.csv file into R environment and the data frame will be named as attacks.\n\n\nCode\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\n\nThis function kable() can be used to review the structure of the imported data frame.\n\n\nCode\nkable(head(attacks))\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores data-time values in POSIXct format\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code\ntz field stores time zone of the source IP address\n\n\n\n\nStep 1: Deriving weekday and hour of days fields\nBefore we plot the calendar heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\n\nCode\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from {lubridate} package, and\n\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\n\nCode\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n\nNote\n\n\n\nBesides extracting the necessary data into attacks data frame, mutate() of dpylr package is used to convert wkday and hours fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble after processing.\n\n\nCode\nkable(head(attacks))\n\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\nCode\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") +\ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the Code Chunk\n\n\n\n\nA tibble data table called grouped is derived by aggregating the attack by wkday and hour fields\nA new field called n is derived by using group_by() and count() functions\nna.omit() is used to exclude missing value\ngeom_tile() is used to plot tiles (grids) at each x and y position\ncolor and size arguments are used to specify the border color and line size of the tiles\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components fo the default ggplot2 have been excluded, this line can be commented out to examine the default plot\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1\nscale_fill_gradient() function is used to create a two colour gradient (low-high)\n\n\n\nThe count is then grouped by hour and wkday and plotted. Since there are values for every combination, there is no need to further preprocess the data.\n\n\n\nTo build multiple heatmaps for the top 4 countries with the highest number of attacks.\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the following:\n\ncount the number of attacjs by country\ncalculate the percent of attacks by country\nsave the results in a tibble data frame\n\n\n\nCode\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2: Preparing the tidy data fram\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\n\nCode\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\n\nStep 3: Plotting Multiple Calendar Heatmap by using ggplot2 package\n\n\nCode\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-data-import",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-data-import",
    "title": "Hands-on Exercise 6",
    "section": "10.4.1 Step 1: Data Import",
    "text": "10.4.1 Step 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\n\n\nCode\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-deriving-month-and-year-field",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-deriving-month-and-year-field",
    "title": "Hands-on Exercise 6",
    "section": "10.4.2 Step 2: Deriving month and year field",
    "text": "10.4.2 Step 2: Deriving month and year field\nTwo new fields called month and year are derived from Month-Year field.\n\n\nCode\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-3-extracting-the-target-country",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-3-extracting-the-target-country",
    "title": "Hands-on Exercise 6",
    "section": "10.4.3 Step 3: Extracting the target country",
    "text": "10.4.3 Step 3: Extracting the target country\n\n\nCode\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-4-computing-year-average-arrivals-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-4-computing-year-average-arrivals-by-month",
    "title": "Hands-on Exercise 6",
    "section": "10.4.4 Step 4: Computing year average arrivals by month",
    "text": "10.4.4 Step 4: Computing year average arrivals by month\n\n\nCode\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-5-plotting-the-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-5-plotting-the-cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "10.4.5 Step 5: Plotting the cycle plot",
    "text": "10.4.5 Step 5: Plotting the cycle plot\n\n\nCode\nwindowsFonts(Helvetica = windowsFont(\"Helvetica\"))\n\n\n\n\nCode\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\n\nIn the code above, the x-axis is not visible, so i have made certain changes by reducing the number of breaks in between the x axis and slanting the words to a certain angle.\n\n\nCode\nggplot() + \n  geom_line(data = Vietnam,\n            aes(x = year, \n                y = `Vietnam`, \n                group = month), \n            colour = \"black\") +\n  geom_hline(data = hline.data,\n             aes(yintercept = avgvalue), \n             linetype = 6, \n             colour = \"red\", \n             size = 0.5) + \n  facet_grid(~month) +\n  labs(title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  scale_x_continuous(breaks = seq(2010, 2020, 4)) +   # Fewer ticks\n  theme_tufte(base_family = \"Helvetica\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate\n\n\n\n\n\n\n\n\n\nAs the grey boxes are not showing even after adding the Helvetica, some panels are added instead.\n\n\nCode\nwindowsFonts(Arial = windowsFont(\"Arial\"))\n\nggplot() + \n  geom_line(data = Vietnam,\n            aes(x = year, \n                y = `Vietnam`, \n                group = month), \n            colour = \"black\") +\n  geom_hline(data = hline.data,\n             aes(yintercept = avgvalue), \n             linetype = 6, \n             colour = \"red\", \n             size = 0.5) + \n  facet_wrap(~month, nrow = 1) +\n  labs(title = \"Visitor arrivals from Vietnam by air, Jan 2010–Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  scale_x_continuous(breaks = seq(2010, 2020, 4)) +\n  theme_tufte(base_family = \"Arial\") +  # Use Arial for Windows compatibility\n  theme(\n    panel.background = element_rect(fill = \"grey95\", colour = \"grey80\"),\n    panel.grid.major = element_line(colour = \"grey80\"),\n    panel.grid.minor = element_line(colour = \"grey90\"),\n    strip.background = element_rect(fill = \"grey85\", colour = \"grey50\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-import-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-import-data",
    "title": "Hands-on Exercise 6",
    "section": "10.5.1 Step 1: Import data",
    "text": "10.5.1 Step 1: Import data\n\n\nCode\nrice &lt;- read_csv(\"data/rice.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-plotting-the-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-plotting-the-slopegraph",
    "title": "Hands-on Exercise 6",
    "section": "10.5.2 Step 2: Plotting the Slopegraph",
    "text": "10.5.2 Step 2: Plotting the Slopegraph\n\n\nCode\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Celin Liaw\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualistion design, factor() is used to convert the value type of Year field from numeric to factor"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#funnelplotr-methods-the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#funnelplotr-methods-the-basic-plot",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.4.1 FunnelPlotR Methods: The Basic Plot",
    "text": "8.4.1 FunnelPlotR Methods: The Basic Plot\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#funnelplotr-methods-makeover-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#funnelplotr-methods-makeover-1",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.4.2 FunnelPlotR Methods: Makeover 1",
    "text": "8.4.2 FunnelPlotR Methods: Makeover 1\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#funnelplotr-methods-makeover-2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#funnelplotr-methods-makeover-2",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.4.3 FunnelPlotR Methods: Makeover 2",
    "text": "8.4.3 FunnelPlotR Methods: Makeover 2\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative \\n Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n) \n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#computing-the-basic-derived-fields",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#computing-the-basic-derived-fields",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.5.1 Computing the basic derived fields",
    "text": "8.5.1 Computing the basic derived fields\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.5.2 Calculate lower and upper limits for 95% and 99.9% CI",
    "text": "8.5.2 Calculate lower and upper limits for 95% and 99.9% CI\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#plotting-a-static-funnel-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#plotting-a-static-funnel-plot",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.5.3 Plotting a static funnel plot",
    "text": "8.5.3 Plotting a static funnel plot\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#interactive-funnel-plot-plotly-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#interactive-funnel-plot-plotly-ggplot2",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.5.4 Interactive Funnel Plot: plotly + ggplot2",
    "text": "8.5.4 Interactive Funnel Plot: plotly + ggplot2\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#using-infer-r-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#using-infer-r-package",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.6.1 Using Infer R Package",
    "text": "8.6.1 Using Infer R Package\nThis package is to perform statistical inference using an expressive statistical grammar that coheres with the tidyverse design framework. There are 4 main verbs that can be used to utilizes to visualize and extract value from their outputs.\n\nstr(covid19)\n\ntibble [267 × 7] (S3: tbl_df/tbl/data.frame)\n $ Sub-district ID: num [1:267] 3.17e+09 3.17e+09 3.18e+09 3.18e+09 3.18e+09 ...\n $ City           : Factor w/ 6 levels \"JAKARTA BARAT\",..: 5 1 4 4 4 3 4 4 2 4 ...\n $ District       : Factor w/ 44 levels \"CAKUNG\",\"CEMPAKA PUTIH\",..: 29 41 24 12 6 26 33 24 42 12 ...\n $ Sub-district   : Factor w/ 267 levels \"ANCOL\",\"ANGKE\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Positive       : num [1:267] 1776 1783 2049 827 2866 ...\n $ Recovered      : num [1:267] 1691 1720 1964 797 2792 ...\n $ Death          : num [1:267] 26 29 31 13 27 26 37 68 38 52 ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#one-numerical-variable-standardised-mean-t-test",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#one-numerical-variable-standardised-mean-t-test",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.6.2 One numerical Variable (Standardised mean t-test)",
    "text": "8.6.2 One numerical Variable (Standardised mean t-test)\nA hypothesis test is created for whether the mean fatality rate differs from fixed value, say 0.01(1%) using a one sample t-test approach.\n\n# Load required packages\npacman::p_load(tidyverse, infer)\n\n# Load and clean data\ncovid19 &lt;- read_csv(\"COVID-19_DKI_Jakarta.csv\") %&gt;%\n  filter(!is.na(Positive), Positive &gt; 0,\n         !is.na(Death), Death &gt;= 0) %&gt;%\n  mutate(fatality_rate = Death / Positive)\n\n# Step 1: Specify the variable of interest\nspec_data &lt;- covid19 %&gt;%\n  specify(response = fatality_rate)\n\n# Step 2: State the null hypothesis (mean fatality rate is 0.01)\nhyp_data &lt;- spec_data %&gt;%\n  hypothesize(null = \"point\", mu = 0.01)\n\n# Step 3: Generate 1000 samples under the null\ngen_data &lt;- hyp_data %&gt;%\n  generate(reps = 1000, type = \"bootstrap\")\n\n# Step 4: Calculate the test statistic (mean)\nnull_dist &lt;- gen_data %&gt;%\n  calculate(stat = \"mean\")\n\n# Step 5: Calculate the observed statistic\nobs_stat &lt;- spec_data %&gt;%\n  calculate(stat = \"mean\")\n\n# Step 6: Visualize with p-value shaded\nvisualize(null_dist) +\n  shade_p_value(obs_stat = obs_stat, direction = \"two-sided\")\n\n\n\n\n\n\n\n\n\nnull_dist %&gt;%\n  get_p_value(obs_stat = obs_stat, direction = \"greater\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0\n\n\n\nThe observed mean (1.6%) is far outside the distribution you’d expect if the true mean were 1%.\nSince the red line lies way in the right tail, this suggests that your observed result is very unlikely under the null hypothesis.\nTherefore, this provides strong evidence against the null hypothesis.\nSince p = 0, we will reject the null hypothesis and that mean fatality rate is significantly greater than 1%"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#alternative-theorey-based-null-distribution",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#alternative-theorey-based-null-distribution",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.6.3 Alternative: Theorey-Based Null Distribution",
    "text": "8.6.3 Alternative: Theorey-Based Null Distribution\nAlternatively, we can visualise it using the observed statistic using the theory-based null distribution: Is the mean fatality rate significantly different from 1% using a theoretical t-distribution?\n\n# Load required packages\npacman::p_load(tidyverse, infer)\n\n# Load and clean data\ncovid19 &lt;- read_csv(\"COVID-19_DKI_Jakarta.csv\") %&gt;%\n  filter(!is.na(Positive) & Positive &gt; 0,\n         !is.na(Death) & Death &gt;= 0) %&gt;%\n  mutate(fatality_rate = Death / Positive)\n\n# 1. Specify variable\nspec_data &lt;- covid19 %&gt;%\n  specify(response = fatality_rate)\n\n# 2. Hypothesize that the population mean = 0.01\nhyp_data &lt;- spec_data %&gt;%\n  hypothesize(null = \"point\", mu = 0.01)\n\n# 3. Calculate the t-statistic under the theory-based null\nobs_t_stat &lt;- hyp_data %&gt;%\n  calculate(stat = \"t\")\n\n# 4. Visualize with theoretical distribution\nvisualize(hyp_data, method = \"theoretical\") +\n  shade_p_value(obs_stat = obs_t_stat, direction = \"two-sided\")\n\n\n\n\n\n\n\n\nObservations from plot:\n\nYour observed t-statistic is far outside the expected range under the null hypothesis.\nThe probability of getting a t-stat this extreme by chance is effectively zero.\nThis provides overwhelming evidence against the null hypothesis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#two-categorical-chi-square-test-of-independence",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part4.html#two-categorical-chi-square-test-of-independence",
    "title": "Hands on Exercise 4 Part 4: Funnel Plots for Fair Comparisons",
    "section": "8.6.4 Two Categorical Chi Square test of independence",
    "text": "8.6.4 Two Categorical Chi Square test of independence\nIs there a relationship between City and Number of Deaths?\nHo: There is no association between City and Number of Deaths\nH1: There is an association between City and Number of Deaths\n\n# Load required packages\npacman::p_load(tidyverse, infer)\n\n# Load and prepare the dataset\ncovid19 &lt;- read_csv(\"COVID-19_DKI_Jakarta.csv\") %&gt;%\n  filter(!is.na(City), !is.na(Death)) %&gt;%\n  mutate(City = as.factor(City),\n         death_bin = cut(Death,\n                         breaks = c(-1, 10, 50, 150, Inf),\n                         labels = c(\"Very Low\", \"Low\", \"Medium\", \"High\")))\n\n# Observed Chi-squared statistic\nChisq_hat &lt;- covid19 %&gt;%\n  specify(City ~ death_bin) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# Null distribution via permutation\nnull_dist &lt;- covid19 %&gt;%\n  specify(City ~ death_bin) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# Plot 1: Simulation-based null distribution\nvisualize(null_dist) +\n  shade_p_value(obs_stat = Chisq_hat, direction = \"greater\")\n\n\n\n\n\n\n\n\nAlternatively, visualising the observed statistic using the theory-based null distribution\n\n# Theoretical null distribution\nnull_dist_theory &lt;- covid19 %&gt;%\n  specify(City ~ death_bin) %&gt;%\n  assume(distribution = \"Chisq\")\n\n# Plot 2: Theoretical chi-square distribution\nvisualize(null_dist_theory) +\n  shade_p_value(obs_stat = Chisq_hat, direction = \"greater\")\n\n\n\n\n\n\n\n\nThe observed statistic using both the null distributions\n\n# Load packages\npacman::p_load(tidyverse, infer)\n\n# Load and prepare data\ncovid19 &lt;- read_csv(\"COVID-19_DKI_Jakarta.csv\") %&gt;%\n  filter(!is.na(City), !is.na(Death)) %&gt;%\n  mutate(City = as.factor(City),\n         death_bin = cut(Death,\n                         breaks = c(-1, 10, 50, 150, Inf),\n                         labels = c(\"Very Low\", \"Low\", \"Medium\", \"High\")))\n\n# 1. Observed Chi-squared statistic\nChisq_hat &lt;- covid19 %&gt;%\n  specify(City ~ death_bin) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# 2. Null distribution via permutation\nnull_dist &lt;- covid19 %&gt;%\n  specify(City ~ death_bin) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# 3. Combined simulation + theory plot\nvisualize(null_dist, method = \"both\") +\n  shade_p_value(obs_stat = Chisq_hat, direction = \"greater\")\n\n\n\n\n\n\n\n\nCalculate the P-Value\n\n# 4. Calculate the p-value\nnull_dist %&gt;%\n  get_p_value(obs_stat = Chisq_hat, direction = \"greater\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0\n\n\nObservations from plots:\n\nYour observed Chi-square value is far beyond what is expected under the null hypothesis of independence\nThe simulation and theory both agree: this is extremely unlikely to happen by chance.\nThis means there is a statistically significant relationship between City and Death level.\nSince p-value = 0, we will reject the null hypothesis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "",
    "text": "Gain hands on experience using:\n\nggstatsplot: to create visual graphics with rich statistical information\nperformance package to visualise model diagnostics\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#installing-and-launching-r-packages",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.1 Installing and Launching R Packages",
    "text": "6.3.1 Installing and Launching R Packages\n\npacman::p_load(tidyverse, ggstatsplot)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#importing-data",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.2 Importing Data",
    "text": "6.3.2 Importing Data\nImporting Exam.csv data using tidyverse packages\n\nexam &lt;- read_csv(\"Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#one-sample-test-gghistostats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#one-sample-test-gghistostats-method",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.3 One-sample test: gghistostats() method",
    "text": "6.3.3 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to build an visual of one-sample test on English scores.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nExplanation of the Results:\nHo: The mean english score is 60\nH1: The mean english score is not equals to 60\n\nlog₁₀(BF₀₁) = -31.45\nThis is the logarithm of the Bayes Factor in favor of the alternative hypothesis over the null:\nThis is extreme evidence in favor of the alternative hypothesis.\nposterior difference = 7.16\nThe estimated mean difference between the observed group and a comparison value (likely a hypothesized mean like 0 or 50), with the observed average English score being significantly higher.\nCI⁹⁵% [5.54, 8.75] (ETI)\nThis is the 95% credible interval (Equal-Tail Interval), suggesting that the true mean difference is very likely between 5.54 and 8.75.\nJZS Cauchy = 0.71\nThis is the scale parameter for the Cauchy prior distribution used in the Bayesian t-test (Jeffreys–Zellner–Siow prior), controlling the expected effect size.\nDashed Blue Line (x = 74.74)\nThis shows the sample mean of the English scores. The peak at this point suggests most scores cluster around here."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#unpacking-the-bayes-factor",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#unpacking-the-bayes-factor",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.4 Unpacking the Bayes Factor",
    "text": "6.3.4 Unpacking the Bayes Factor\n\nBayes Factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It is a measure of strength of evidence in favor of one theory among 2 competing theories\nIt gives us a way to evaluate the data in favor of a null hypothesis based on external information and tells us the weight of evidence is in favor of the hypothesis\nBayes factor is often written as B10 and can be defined mathematically as”\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#how-to-interpret-bayes-factor",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#how-to-interpret-bayes-factor",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.5 How to interpret Bayes Factor",
    "text": "6.3.5 How to interpret Bayes Factor\nIt can be any positive number and can be interpreted in the table below:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#two-sample-mean-test-ggbetweenstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#two-sample-mean-test-ggbetweenstats",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.6 Two-sample mean test: ggbetweenstats()",
    "text": "6.3.6 Two-sample mean test: ggbetweenstats()\nThe code ggbetweenstats() is used to build a visual for two-sample mean test of Math scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nSummary of results from plot:\n\nTest used: W_Mann–Whitney = 13011.00\nThis is a non-parametric alternative to the t-test (used when data may not be normally distributed).\np-value = 0.91\n➤ This is not statistically significant. A high p-value (much greater than 0.05) suggests no evidence to reject the null hypothesis.\nIn other words, there is no significant difference in Maths scores between males and females.\nMedian (Female) = 74, Median (Male) = 75\n➤ Scores are nearly identical in central tendency.\nRank biserial correlation = 0.007\n➤ This is a very small effect size, indicating negligible practical difference.\n95% CI = [−0.12, 0.13]\n➤ The confidence interval for the effect size includes 0, further confirming that there’s no meaningful difference\nn = 322\n➤ Total number of observations (170 females, 152 males)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#oneway-anova-test-ggbetweenstats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#oneway-anova-test-ggbetweenstats-method",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.7 Oneway ANOVA Test: ggbetweenstats() method",
    "text": "6.3.7 Oneway ANOVA Test: ggbetweenstats() method\nThe code ggbetweenstats() is used to build a visual for one-way ANOVA test on English score by race.\n\n“ns” - only non-significant\n“s” - only significant\n“all” - everything\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nSummary of results from plot:\n\nWelch’s ANOVA:\n\nF(3,23.8)=10.15,p=1.71×10−4F(3, 23.8) = 10.15,p = 1.71 ^{-4}F(3,23.8)=10.15,p=1.71×10−4\n➤ The p-value is very small, indicating a statistically significant difference in English scores among the racial groups.\n\nEffect size (ω²) = 0.50\n➤ This is a very large effect, suggesting race explains a substantial proportion of variance in English scores.\nCI₉₅% [0.21, 1.00] for ω²\n➤ Confirms the effect size is meaningful.\nn = 322\n➤ Sample size (with group sizes shown under each violin).\np (FDR-adjusted) = 5.19e-06\n➤ Adjusted p-value from Games–Howell pairwise comparisons — confirms at least one pairwise difference is significant.\n\n\n6.3.7.1 ggbetweenstats - Summary of tests\nFollowing (between-subjects) tests are carried out for each type of analyses"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#significant-test-of-correlation-ggscatterstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#significant-test-of-correlation-ggscatterstats",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.8 Significant Test of Correlation: ggscatterstats()",
    "text": "6.3.8 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\nSummary of results from plot:\n\nPearson correlation ​=0.83:\n➤ This indicates a very strong positive correlation — students who score well in Maths tend to also score well in English.\np-value = 1.70e-83\n➤ This is an extremely small p-value, so the correlation is highly statistically significant.\n95% CI for r: [0.79, 0.86]\n➤ The confidence interval confirms the correlation is both strong and precise.\nt(320) = 26.72\n➤ The test statistic for evaluating correlation; much larger than typical critical values.\nn = 322 pairs\n➤ Total number of students with both scores available."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#significant-test-of-association-dependence-ggbarstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part2.html#significant-test-of-association-dependence-ggbarstats-methods",
    "title": "Hands on Exercise 4 Part 2: Visual Statistical Analysis",
    "section": "6.3.9 Significant Test of Association (Dependence): ggbarstats() methods",
    "text": "6.3.9 Significant Test of Association (Dependence): ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\nSummary of results from plot:\n\nChi-squared test χPearson2(3)=1.04, p=0.79^2_{}(3) = 1.04, p = 0.79χPearson2​(3)=1.04, p=0.79\n➤ Not statistically significant, meaning there’s no evidence of an association between gender and Maths score bins.\nCramér’s V = 0.00, with 95% CI [0.00, 0.08]\n➤ Effect size is negligible. There is no practical difference between the two gender groups in how their Maths scores are distributed.\nSample size n=322n = 322n=322:\n170 females and 152 males"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands on Exercise 3 Part 1",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-statistics-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-statistics-on-tooltip",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.6.1 Displaying Statistics on tooltip",
    "text": "3.6.1 Displaying Statistics on tooltip\n\nComputing 90% Confidence Interval of the mean\nDerived statistics are displayed in the tooltip\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.6.2 Hover effect with data_id aesthetic",
    "text": "3.6.2 Hover effect with data_id aesthetic\n\nInteractive feature of ggiraph, data_id\nAnything associated with data_id = CLASS will be highlighted if you hover over it\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#styling-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#styling-hover-effect",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.6.3 Styling Hover Effect",
    "text": "3.6.3 Styling Hover Effect\n\nCss codes are used to change the highlighting effect\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-tooltip-and-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-tooltip-and-hover-effect",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.6.4 Combining tooltip and hover effect",
    "text": "3.6.4 Combining tooltip and hover effect\n\nElements associated with data_id = CLASS will be highlighted upon mouse over\nTooltip will also show the CLASS\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#click-effect-with-onclick",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#click-effect-with-onclick",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.6.5 Click effect with onclick",
    "text": "3.6.5 Click effect with onclick\n\nonclick provides hotlink interactivity on the web\nWeb document link with a data object will be displayed on the web browser upon mouse click\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.6.6 Coordinated Multiple Views with ggiraph",
    "text": "3.6.6 Coordinated Multiple Views with ggiraph\n\nWhen a data point on one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too\nThe following strategies will be used:\nAppropriate interactive functions of ggiraph to create the multiple views\npatchwork function of patchwork package will be used inside girafe function to create interactive coordinated multiple views\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.7.1 Creating an interactive scatter plot: plot_ly() method",
    "text": "3.7.1 Creating an interactive scatter plot: plot_ly() method\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-visual-variable-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-visual-variable-plot_ly-method",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.7.2 Working with visual variable: plot_ly() method",
    "text": "3.7.2 Working with visual variable: plot_ly() method\n\ncolor argument is mapped to a qualitative visual variable (i.e. RACE)\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.7.3 Creating an interactive scatter plot: ggplotly() method",
    "text": "3.7.3 Creating an interactive scatter plot: ggplotly() method\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-plotly",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.7.4 Coordinated Multiple Views with plotly",
    "text": "3.7.4 Coordinated Multiple Views with plotly\n\nhighlight_key() of plotly package is used as shared data\ntwo scatterplots will be created by using ggplot2 functions\nsubplot() of plotly package is used to place them next to each other side-by-side\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-table-dt-package",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-table-dt-package",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.8.1 Interactive Data Table: DT Package",
    "text": "3.8.1 Interactive Data Table: DT Package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny)\n\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#linked-brushing-crosstalk-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#linked-brushing-crosstalk-method",
    "title": "Hands on Exercise 3 Part 1",
    "section": "3.8.2 Linked brushing: crosstalk method",
    "text": "3.8.2 Linked brushing: crosstalk method\nLearning points:\n\nhighlight() is a function of plotly package. It sets a variety of options for highlighting multiple plot. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they willl be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they willl be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a simple bar chart",
    "text": "Plotting a simple bar chart\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-bar-chart-of-science-score-distribution",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-bar-chart-of-science-score-distribution",
    "title": "Hands-on Exercise 1",
    "section": "Plotting Bar Chart of Science score Distribution",
    "text": "Plotting Bar Chart of Science score Distribution\n\nggplot(data=exam_data, aes(x = SCIENCE)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"Yellow\", \n                 fill=\"Blue\") +\n  ggtitle(\"Distribution of Science scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-box-plot-of-the-english-scores-of-the-different-races",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-box-plot-of-the-english-scores-of-the-different-races",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Box Plot of the English scores of the different races",
    "text": "Plotting a Box Plot of the English scores of the different races\n\nggplot(data=exam_data, \n       aes(y = ENGLISH, \n           x= RACE)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-scatter-plot-of-the-science-vs-math-scores",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-scatter-plot-of-the-science-vs-math-scores",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Scatter Plot of the Science vs Math scores",
    "text": "Plotting a Scatter Plot of the Science vs Math scores\n\nggplot(data=exam_data, \n       aes(x= SCIENCE, y=MATHS)) +\n  geom_point() +\n  geom_smooth(size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-line-graph-of-the-scores-of-the-different-classes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-line-graph-of-the-scores-of-the-different-classes",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Line graph of the scores of the different classes",
    "text": "Plotting a Line graph of the scores of the different classes"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-violin-plot-of-science-scores-in-the-different-classes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-violin-plot-of-science-scores-in-the-different-classes",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Violin Plot of science scores in the different classes",
    "text": "Plotting a Violin Plot of science scores in the different classes\n\nggplot(data=exam_data, \n       aes(y = SCIENCE, \n           x= CLASS)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-age-sex-pyramid-using-class-as-proxy-for-age-group",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-age-sex-pyramid-using-class-as-proxy-for-age-group",
    "title": "Hands-on Exercise 1",
    "section": "Plotting Age-Sex Pyramid (Using CLASS as Proxy for Age Group)",
    "text": "Plotting Age-Sex Pyramid (Using CLASS as Proxy for Age Group)\n\npyramid_data &lt;- exam_data %&gt;% group_by(CLASS, GENDER) %&gt;% summarise(Count = n(), .groups = \"drop\") %&gt;% mutate(Count = ifelse(GENDER == \"Male\", -Count, Count))\n\nggplot(pyramid_data, aes(x = CLASS, y = Count, fill = GENDER)) + geom_bar(stat = \"identity\") + coord_flip() + labs(title = \"Class-Gender Pyramid\", x = \"Class\", y = \"Number of Students\") + theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-pareto-chart-of-race",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-pareto-chart-of-race",
    "title": "Hands-on Exercise 1",
    "section": "Plotting Pareto Chart of Race",
    "text": "Plotting Pareto Chart of Race\n\npacman::p_load(qcc)\n\nrace_freq &lt;- exam_data %&gt;%\n  count(RACE, sort = TRUE)\n\npareto.chart(race_freq$n, names = race_freq$RACE,\n             main = \"Pareto Chart of Race\")\n\n\n\n\n\n\n\n\n   \nPareto chart analysis for race_freq$n\n     Frequency  Cum.Freq. Percentage Cum.Percent.\n  A 193.000000 193.000000  59.937888    59.937888\n  B 108.000000 301.000000  33.540373    93.478261\n  C  12.000000 313.000000   3.726708    97.204969\n  D   9.000000 322.000000   2.795031   100.000000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-trellis-display-for-english-scores",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-trellis-display-for-english-scores",
    "title": "Hands-on Exercise 1",
    "section": "Plotting Trellis Display for English Scores",
    "text": "Plotting Trellis Display for English Scores\n\nlibrary(tidyverse)\n\n# Reshape to long format\nlong_avg_data &lt;- exam_data %&gt;%\n  pivot_longer(cols = c(ENGLISH), \n               names_to = \"Subject\", \n               values_to = \"Score\") %&gt;%\n  group_by(CLASS, GENDER, Subject) %&gt;%\n  summarise(Avg_Score = mean(Score, na.rm = TRUE), .groups = \"drop\")\n\n# Set custom shapes and colors\ngender_shapes &lt;- c(\"Female\" = 16, \"Male\" = 3)  # Circle and cross\ngender_colors &lt;- c(\"Female\" = \"darkgreen\", \"Male\" = \"orangered\")\n\n# Plot\nggplot(long_avg_data, aes(x = Avg_Score, y = Subject, color = GENDER, shape = GENDER)) +\n  geom_point(size = 3) +\n  facet_wrap(~ CLASS, ncol = 1, strip.position = \"right\") +\n  scale_color_manual(values = gender_colors) +\n  scale_shape_manual(values = gender_shapes) +\n  labs(\n    title = \"Average English Scores and Gender Across Classes\",\n    x = \"Average Score\",\n    y = NULL,\n    color = \"Gender\",\n    shape = \"Gender\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    strip.text = element_text(face = \"bold\", size = 12),\n    axis.text.y = element_text(size = 11, hjust = 1),  # Justified and consistent label styling\n    panel.spacing = unit(1, \"lines\"),\n    legend.position = \"top\",\n    strip.background = element_blank(),  # Optional: remove background for facet labels\n    axis.title.y = element_blank()  # Remove y-axis title for more space\n  ) +\n  scale_y_discrete(labels = function(x) str_wrap(x, width = 10))  # Wrap y-axis labels"
  },
  {
    "objectID": "GroupProject/grpproject/Proposal.html",
    "href": "GroupProject/grpproject/Proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "We have chosen Mini Case Challenge 3 -Visualizing Communications and Influence in Oceanus and the link to the challenge can be found here."
  },
  {
    "objectID": "GroupProject/grpproject/Proposal.html#proposal-visual-analytics-platform-for-investigative-journalism-in-oceanus",
    "href": "GroupProject/grpproject/Proposal.html#proposal-visual-analytics-platform-for-investigative-journalism-in-oceanus",
    "title": "Project Proposal",
    "section": "",
    "text": "We have chosen Mini Case Challenge 3 -Visualizing Communications and Influence in Oceanus and the link to the challenge can be found here."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, My name is Celin! This webpage will detail all my learnings from ISSS608 Visual Analytics Course."
  },
  {
    "objectID": "GroupProject/grpproject/Team_Member.html",
    "href": "GroupProject/grpproject/Team_Member.html",
    "title": "The Members",
    "section": "",
    "text": "We developed this project for ISSS608 (Visual Analytics and Applications module) in Singapore Management University under Dr. Kam Tin Seong. The members of this team are:\n\nLiaw Ying Ting Celin\nNg Wee Tinn Shermainn\nStefanie Felicia"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\nexam_data &lt;- read_csv(\"Exam_data.csv\")\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overlapping-annotations",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overlapping-annotations",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-ggrepel-to-repel-overlapping-text",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-ggrepel-to-repel-overlapping-text",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "ggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#classic-theme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#classic-theme",
    "title": "Hands-on Exercise 2",
    "section": "Classic Theme",
    "text": "Classic Theme\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_classic() +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#economist-theme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#economist-theme",
    "title": "Hands-on Exercise 2",
    "section": "Economist Theme",
    "text": "Economist Theme\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(base_family = \"sans\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-ggplot2-graphs",
    "title": "Hands-on Exercise 2",
    "section": "Combining ggplot2 graphs",
    "text": "Combining ggplot2 graphs\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\",\n              base_family = \"sans\")\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-2-plots-side-by-side",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-2-plots-side-by-side",
    "title": "Hands-on Exercise 2",
    "section": "Combining 2 Plots side by side",
    "text": "Combining 2 Plots side by side\n\np1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-3-graphs---using-to-stack-2-graphs-and-to-place-the-plots-beside-each-other",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-3-graphs---using-to-stack-2-graphs-and-to-place-the-plots-beside-each-other",
    "title": "Hands-on Exercise 2",
    "section": "Combining 3 graphs - Using “/” to stack 2 graphs and “|” to place the plots beside each other",
    "text": "Combining 3 graphs - Using “/” to stack 2 graphs and “|” to place the plots beside each other\n\n(p1 / p2) | p3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#placing-plots-next-to-each-other-based-on-the-provided-layout---using-inset_element",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#placing-plots-next-to-each-other-based-on-the-provided-layout---using-inset_element",
    "title": "Hands-on Exercise 2",
    "section": "Placing plots next to each other based on the provided layout - using inset_element",
    "text": "Placing plots next to each other based on the provided layout - using inset_element\ninset_element:\n\nLeft = 0.02 - left edge start 2% from left side of the main plot\nBottom = 0.7 - Bottom edge start 70% from the bottom of the main plot (Near the top)\nRight = 0.5 - Right edge ends at 50% of the width\ntop = 1 top edge ends at 100% of height\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-patchwork-and-theme-together",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-patchwork-and-theme-together",
    "title": "Hands-on Exercise 2",
    "section": "Using patchwork and theme together",
    "text": "Using patchwork and theme together\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-box-plot-of-the-english-scores-of-the-different-classes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-box-plot-of-the-english-scores-of-the-different-classes",
    "title": "Hands-on Exercise 2",
    "section": "Plotting a Box Plot of the English scores of the different classes",
    "text": "Plotting a Box Plot of the English scores of the different classes\n\nFrom the box plot below, there is a downward trend of English scores from 3A to 3I, showing that students from Class 3A generally scored better than students in the other classes\nThere are also some classes with outliers, for example class 3E and 3F where there are one or more students who scored significantly lower than the rest of the class\n\n\nggplot(data=exam_data, aes(y = ENGLISH, x= CLASS)) + geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-violin-plot-of-science-scores-in-the-different-races",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-violin-plot-of-science-scores-in-the-different-races",
    "title": "Hands-on Exercise 2",
    "section": "Plotting a Violin Plot of science scores in the different Races",
    "text": "Plotting a Violin Plot of science scores in the different Races\n\nFrom the violin plot, it can be seen that there is a majority of “Chinese” students who scored in the 75 range and “Other” students scoring in the 68 range for science subject\nFor Indian students, their science scores are quite evenly spread out from 12.5 to 87.5\n\n\nggplot(data=exam_data, \n       aes(y = SCIENCE, \n           x= RACE)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-pie-chart-of-the-proportion-of-the-different-races",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-pie-chart-of-the-proportion-of-the-different-races",
    "title": "Hands-on Exercise 2",
    "section": "Plotting a pie chart of the proportion of the different races",
    "text": "Plotting a pie chart of the proportion of the different races\n\nIt can be seen from the pie chart that more than half of the student population are Chinese and the next majority is Malay\nThe Indian and Other students seem to have the same proportion\n\n\nlibrary(dplyr)\nrace_counts &lt;- exam_data %&gt;%\n  count(RACE)\n\nggplot(race_counts, aes(x = \"\", y = n, fill = RACE)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  labs(title = \"Student Distribution by Race\",\n       y = NULL,\n       x = NULL,\n       fill = \"Race\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 16))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#raincloud-plots-of-scores-by-gender",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#raincloud-plots-of-scores-by-gender",
    "title": "Hands-on Exercise 2",
    "section": "Raincloud Plots of Scores by Gender",
    "text": "Raincloud Plots of Scores by Gender\n\nlibrary(ggdist)\n\n# ensure GENDER is a factor\nexam_data$GENDER &lt;- as.factor(exam_data$GENDER)\n\na1 &lt;- ggplot(exam_data, aes(x = ENGLISH, y = GENDER, fill = GENDER)) +\n  # lighter half-density cloud\n  stat_halfeye(\n    side          = \"right\",\n    adjust        = 0.5,\n    width         = 0.6,\n    justification = 0.1,\n    .width        = 0,\n    point_colour  = NA,\n    alpha         = 0.3\n  ) +\n  # central boxplot\n  geom_boxplot(\n    width         = 0.12,\n    outlier.shape = NA,\n    position      = position_nudge(y = 0.2),\n    alpha         = 0.8\n  ) +\n  # jittered points on top\n  geom_jitter(\n    width  = 0,\n    height = 0.15,\n    size   = 1.5,\n    alpha  = 0.6,\n    aes(color = GENDER)\n  ) +\n  # matching palette\n  scale_fill_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  scale_color_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  # side-by-side panels\n  facet_wrap(~ GENDER, nrow = 1, scales = \"free_y\") +\n  theme_ipsum_rc(base_size = 12) +\n  labs(\n    title = \"Raincloud Plot of English Scores by Gender\",\n    x     = \"English Score\",\n    y     = NULL\n  ) +\n  theme(\n    legend.position    = \"none\",\n    axis.text.y        = element_blank(),\n    axis.ticks.y       = element_blank(),\n    panel.grid.major.y = element_blank()\n  )\n\n\n# ensure GENDER is a factor\nexam_data$GENDER &lt;- as.factor(exam_data$GENDER)\n\na2 &lt;- ggplot(exam_data, aes(x = MATHS, y = GENDER, fill = GENDER)) +\n  # lighter half-density cloud\n  stat_halfeye(\n    side          = \"right\",\n    adjust        = 0.5,\n    width         = 0.6,\n    justification = 0.1,\n    .width        = 0,\n    point_colour  = NA,\n    alpha         = 0.3\n  ) +\n  # central boxplot\n  geom_boxplot(\n    width         = 0.12,\n    outlier.shape = NA,\n    position      = position_nudge(y = 0.2),\n    alpha         = 0.8\n  ) +\n  # jittered points on top\n  geom_jitter(\n    width  = 0,\n    height = 0.15,\n    size   = 1.5,\n    alpha  = 0.6,\n    aes(color = GENDER)\n  ) +\n  # matching palette\n  scale_fill_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  scale_color_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  # side-by-side panels\n  facet_wrap(~ GENDER, nrow = 1, scales = \"free_y\") +\n  theme_ipsum_rc(base_size = 12) +\n  labs(\n    title = \"Raincloud Plot of Maths Scores by Gender\",\n    x     = \"English Score\",\n    y     = NULL\n  ) +\n  theme(\n    legend.position    = \"none\",\n    axis.text.y        = element_blank(),\n    axis.ticks.y       = element_blank(),\n    panel.grid.major.y = element_blank()\n  )\n\n\n# ensure GENDER is a factor\nexam_data$GENDER &lt;- as.factor(exam_data$GENDER)\n\na3 &lt;- ggplot(exam_data, aes(x = SCIENCE, y = GENDER, fill = GENDER)) +\n  # lighter half-density cloud\n  stat_halfeye(\n    side          = \"right\",\n    adjust        = 0.5,\n    width         = 0.6,\n    justification = 0.1,\n    .width        = 0,\n    point_colour  = NA,\n    alpha         = 0.3\n  ) +\n  # central boxplot\n  geom_boxplot(\n    width         = 0.12,\n    outlier.shape = NA,\n    position      = position_nudge(y = 0.2),\n    alpha         = 0.8\n  ) +\n  # jittered points on top\n  geom_jitter(\n    width  = 0,\n    height = 0.15,\n    size   = 1.5,\n    alpha  = 0.6,\n    aes(color = GENDER)\n  ) +\n  # matching palette\n  scale_fill_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  scale_color_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  # side-by-side panels\n  facet_wrap(~ GENDER, nrow = 1, scales = \"free_y\") +\n  theme_ipsum_rc(base_size = 12) +\n  labs(\n    title = \"Raincloud Plot of Science Scores by Gender\",\n    x     = \"English Score\",\n    y     = NULL\n  ) +\n  theme(\n    legend.position    = \"none\",\n    axis.text.y        = element_blank(),\n    axis.ticks.y       = element_blank(),\n    panel.grid.major.y = element_blank()\n  )\n\nUsing “/” to combine the charts, we can get the figures below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#diverging-stacked-bar-chart-split-by-gender",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#diverging-stacked-bar-chart-split-by-gender",
    "title": "Hands-on Exercise 2",
    "section": "Diverging Stacked Bar Chart split by Gender",
    "text": "Diverging Stacked Bar Chart split by Gender\nThe subjects are split into 3 bands for each subject: Low(0-39), Medium(40-69), High(70-100).\nFrom the charts, there are more females in the High band for English and Science Subjects while the Math subjects are more or less equal for both females and males.\nIn the medium band for English, there are more males then females while for Math and Science, there are more females than males.\nIn the low band, however, there are consistently more males than females.\nTo conclude, females generally score higher for English and Science subjects and score higher than males in general.\n\n# Load libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(forcats)\n\n# 1. Categorize each subject into performance bands\nexam_bands &lt;- exam_data %&gt;%\n  mutate(\n    ENGLISH_BAND = cut(ENGLISH, breaks = c(-Inf, 39, 69, 100),\n                       labels = c(\"Low\", \"Medium\", \"High\")),\n    MATHS_BAND   = cut(MATHS,   breaks = c(-Inf, 39, 69, 100),\n                       labels = c(\"Low\", \"Medium\", \"High\")),\n    SCIENCE_BAND = cut(SCIENCE, breaks = c(-Inf, 39, 69, 100),\n                       labels = c(\"Low\", \"Medium\", \"High\"))\n  )\n\n# 2. Reshape data to long format for faceting\nlong_bands &lt;- exam_bands %&gt;%\n  select(GENDER, ENGLISH_BAND, MATHS_BAND, SCIENCE_BAND) %&gt;%\n  pivot_longer(cols = ends_with(\"_BAND\"),\n               names_to = \"SUBJECT\",\n               values_to = \"PERFORMANCE\") %&gt;%\n  mutate(\n    SUBJECT = recode(SUBJECT,\n                     ENGLISH_BAND = \"English\",\n                     MATHS_BAND = \"Maths\",\n                     SCIENCE_BAND = \"Science\"),\n    PERFORMANCE = factor(PERFORMANCE, levels = c(\"Low\", \"Medium\", \"High\"))\n  )\n\n# 3. Prepare data for plotting\nplot_data &lt;- long_bands %&gt;%\n  count(SUBJECT, GENDER, PERFORMANCE) %&gt;%\n  mutate(n = ifelse(GENDER == \"Male\", -n, n))\n\n# 4. Create diverging stacked bar chart with facets\nggplot(plot_data, aes(x = PERFORMANCE, y = n, fill = GENDER)) +\n  geom_bar(stat = \"identity\", width = 0.7) +\n  coord_flip() +\n  facet_wrap(~ SUBJECT, ncol = 1, scales = \"free_y\") +\n  scale_y_continuous(labels = abs) +\n  scale_fill_manual(values = c(\"Female\" = \"#00AFBB\", \"Male\" = \"#FC4E07\")) +\n  labs(\n    title = \"Diverging Stacked Bar Charts: Performance Bands by Gender\",\n    x = \"Performance Band\",\n    y = \"Number of Students\"\n  ) +\n  theme_minimal(base_size = 14)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "",
    "text": "Creating animated data visualisation by using gganimate and plotly r packages\nLearn how to reshape data by using tidyr package\nProcess, wrangle and transform data by using dplyr package\n\n\n\n\nPlots do not move\nMany individual plots are built and stitched together as movie frames\nEach frame is a different plot and subset drives the flow of the animation when stitched back together\n\n\n\n\n\nFrame: Represents a different point in time or a different category\nAnimation Attributes: Settings that control how the animation behaves"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#basic-concepts-of-animation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#basic-concepts-of-animation",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "",
    "text": "Plots do not move\nMany individual plots are built and stitched together as movie frames\nEach frame is a different plot and subset drives the flow of the animation when stitched back together"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#terminology",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#terminology",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "",
    "text": "Frame: Represents a different point in time or a different category\nAnimation Attributes: Settings that control how the animation behaves"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#loading-the-r-packages",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "4.2.1 Loading the R packages",
    "text": "4.2.1 Loading the R packages\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#importing-the-data",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "4.2.2 Importing the data",
    "text": "4.2.2 Importing the data\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-a-static-population-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-a-static-population-bubble-plot",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "4.3.1 Building a static population bubble plot",
    "text": "4.3.1 Building a static population bubble plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-the-animated-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-the-animated-bubble-plot",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "4.3.2 Building the animated bubble plot",
    "text": "4.3.2 Building the animated bubble plot\n\nTransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year)\nease_aes() is used to control easing of aesthetics: Default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back and bounce\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "4.4.1 Building an animated bubble plot: ggplotly() method",
    "text": "4.4.1 Building an animated bubble plot: ggplotly() method\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\nEven though show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position=‘none’) should be used.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_Part2.html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "Hands-on Exercise 3 Part 2",
    "section": "4.4.2 Building an animated bubble plot: plot_ly() method",
    "text": "4.4.2 Building an animated bubble plot: plot_ly() method\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "",
    "text": "In this chapter, we will be learning ridgeline plot and raincloud plot using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.2.1 Installing and loading the packages",
    "text": "4.2.1 Installing and loading the packages\nThe following R Packages will be used:\n\nggridges - a ggplot2 extension designed for plotting ridgeline plots\nggdist - a ggplot2 extension designed for visualising distribution and uncertainty\ntidyverse - a family of R packages to meet the modern data science and visual communication needs\nggthemes - a ggplot extension that provides the user additional themes, scales and geoms for the ggplots package\ncolorspace - an R package that provides a broad toolbox for selecting individual color or color palettes\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#importing-data",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.2.2 Importing Data",
    "text": "4.2.2 Importing Data\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#plotting-ridgeline-graph-ggridges-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#plotting-ridgeline-graph-ggridges-method",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.3.1 Plotting ridgeline graph: ggridges method",
    "text": "4.3.1 Plotting ridgeline graph: ggridges method\nGgridges provides two main geom to plot gridgeline plots: geom_ridgeline() and geom_density_ridges(). The first one uses height values directly to draw the ridgelines and the second one estimates data densities and draw them using ridgelines.\n\nThe plotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#varying-fill-colors-along-the-x-axis",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#varying-fill-colors-along-the-x-axis",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.3.2 Varying fill colors along the x axis",
    "text": "4.3.2 Varying fill colors along the x axis\nTo fill the area under a ridgeline with colors that vary along the x axis, we can use geom_ridgeline_gradient() or geom_density_ridges(). Both geoms work just like geom_ridgeline() and geom_density_ridgeline() except that they allow for varying fill colors. It does not allow for alpha transparency in the fill. Only can have changing fill colors or transparency, but not both.\n\nThe plotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#mapping-the-probabilities-directly-onto-colour",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#mapping-the-probabilities-directly-onto-colour",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.3.3 Mapping the probabilities directly onto colour",
    "text": "4.3.3 Mapping the probabilities directly onto colour\nThe ggridges package has a stat function called stat_density_ridges() and is used to replace stat_density() of ggplot2.\nThe figure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\nThe argument calc_ecdf = TRUE has to be added in stat_density_ridges()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#ridgeline-plots-with-quantile-lines",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#ridgeline-plots-with-quantile-lines",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.3.4 Ridgeline plots with quantile lines",
    "text": "4.3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient() the ridgeline plot can be colored by quantile, using calculated stat(quantile_ aesthetic as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#plotting-a-half-eye-graph",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#plotting-a-half-eye-graph",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.4.1 Plotting a Half Eye Graph",
    "text": "4.4.1 Plotting a Half Eye Graph\nA half-eye graph is plotted using stat_halfeye() of ggdist package.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n[!TIP] Things to learn from the code chunk above\nWe remove the slab interval by setting .width = 0 and point_colour = NA."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#adding-the-boxplot-with-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#adding-the-boxplot-with-geom_boxplot",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.4.2 Adding the boxplot with geom_boxplot()",
    "text": "4.4.2 Adding the boxplot with geom_boxplot()\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#adding-the-dot-plots-with-stat_dots",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#adding-the-dot-plots-with-stat_dots",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.4.3 Adding the Dot Plots with stat_dots()",
    "text": "4.4.3 Adding the Dot Plots with stat_dots()\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part1.html#finishing-touch",
    "title": "Hands-on Exercise 4 Part 1: Visualising Distribution",
    "section": "4.4.4 Finishing Touch",
    "text": "4.4.4 Finishing Touch\nLastly, coord_flip() of ggplot2 will be used to flip the raincloud chart horizontally to give the raincloud appearance.\nThe theme economist of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html",
    "title": "Hands on Exercise 4 Part 3",
    "section": "",
    "text": "In this chapter, statistical graphics for visualising uncertainty will be created. Items learnt in this chapter includes:\n\nTo plot statistics error bars by using ggplot2\nTo plot interactive error bars by combining ggplot2, plotly and DT\nTo create advanced by using ggdist\nTo create hypothetical outcome plots (HOPs) by using ungeviz package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#installing-and-loading-the-packages",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.2.1 Installing and loading the packages",
    "text": "7.2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used:\n\ntidyverse\nplotly\ngganimate\nDT\ncrosstalk\nggdist\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#data-import",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.2.2 Data Import",
    "text": "7.2.2 Data Import\n\nexam &lt;- read_csv(\"Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#plotting-standard-error-bars-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#plotting-standard-error-bars-of-point-estimates",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.3.1 Plotting standard error bars of point estimates",
    "text": "7.3.1 Plotting standard error bars of point estimates\nThe plot will be the standard error bars of mean math score by race.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean +/- se.\nFor geom_point(), it is important to indicate stat = \"identity\"."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#plotting-confidence-interval-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.3.2 Plotting Confidence Interval of Point Estimates",
    "text": "7.3.2 Plotting Confidence Interval of Point Estimates\nWe can also plot the confidence intervals of mean math scores by race.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se\nThe error bars are sorted by using the average math scores\nlabs() argument of ggplot2 is used to change the x-axis label"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.3.3 Visualizing the uncertainty of point estimates with interactive error bars",
    "text": "7.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, interactive error bars for the 99% confidence interval of mean math scores by race are plotted.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.4.1 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "7.4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of math scores by race\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nFor example, in the code chunk the following arguments are added:\n\nwidth = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.4.2 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "7.4.2 Visualizing the uncertainty of point estimates: ggdist methods\nMakeover the previous plot on the previous slide by showing 95% and 99% confidence intervals\n\nlibrary(ggdist)\nlibrary(tidyverse)\n\n# Precompute median and multiple intervals (95% and 99%)\nexam_summary &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  median_qi(MATHS, .width = c(0.95, 0.99))\n\n# Plot with transparent intervals\nggplot(exam_summary, aes(x = RACE, y = MATHS, ymin = .lower, ymax = .upper)) +\n  geom_pointrange(aes(color = factor(.width)), \n                  position = position_dodge(width = 0.5),\n                  linewidth = 1.2,\n                  alpha = 0.6) +\n  scale_color_manual(\n    values = c(\"0.95\" = \"#1f77b4\",  # Blue\n               \"0.99\" = \"#d62728\")  # Red\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Median Math Score\",\n    subtitle = \"95% (blue) and 99% (red) intervals\",\n    color = \"Interval Width\",\n    y = \"Math Score\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-2",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.4.3 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "7.4.3 Visualizing the uncertainty of point estimates: ggdist methods\n\nIn the code below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of math scores by race\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#installing-ungeviz-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#installing-ungeviz-package",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.5.1 Installing ungeviz package",
    "text": "7.5.1 Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#launch-the-application-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#launch-the-application-in-r",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.5.2 Launch the Application in R",
    "text": "7.5.2 Launch the Application in R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_Part3.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands on Exercise 4 Part 3",
    "section": "7.5.3 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "7.5.3 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nlibrary(ungeviz)\nlibrary(ggplot2)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3,\n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n# Horizontal line summarize group level means or medians for variable maths\n# Speed of orange moving bar shows the certainty of the data\n# If it is moving slowly, means that it is certain of the data and if it is moving fast, means that it is uncertain of the data\n# Does not mean more data then it will be more certain"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-edges-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-edges-data",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.1 The Edges Data",
    "text": "9.3.1 The Edges Data\n\nGAStech_email_edge-v2.csv consists of the names, department and title of 55 employees"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-nodes-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-nodes-data",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.2 The Nodes Data",
    "text": "9.3.2 The Nodes Data\n\nGAStech_email_nodes.csv consists of the names, department and title of the 55 employees"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#importing-network-data-from-files",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#importing-network-data-from-files",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.3 Importing network data from files",
    "text": "9.3.3 Importing network data from files\nIn this step, GAStech_email_node.csv and GAStech_email_edges-v2.csv will be imported into Rstudio environment by using read_csv of readr package.\n\n\nCode\nGAStech_nodes &lt;- read_csv(\"GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-imported-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-imported-data",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.4 Reviewing Imported Data",
    "text": "9.3.4 Reviewing Imported Data\nNext, the structure of the data frame will be examined using glimpse() of dplyr.\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above revelas that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date” data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#wrangling-time",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#wrangling-time",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.5 Wrangling Time",
    "text": "9.3.5 Wrangling Time\n\n\nCode\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keeps the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field\nthe values in the weekday field are in ordinal scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-revised-date-fields",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-revised-date-fields",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.6 Reviewing the revised date fields",
    "text": "9.3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#wrangling-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#wrangling-attributes",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.7 Wrangling Attributes",
    "text": "9.3.7 Wrangling Attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise() and ungroup()\nThe output data.frame is called GAStech_edges_aggregated\nA new field called Weight has been added in GAStech_edges_aggregated"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-revised-edges-file",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-revised-edges-file",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.3.8 Reviewing the revised edges file",
    "text": "9.3.8 Reviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-tbl_graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-tbl_graph-object",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.4.1 The tbl_graph object",
    "text": "9.4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph net work object from nodes and edges data\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame\ndata.frame, lst, matrix from base\nigraph from igraph\nnetwork from network\ndendogram and hclust from stats\nNode from data.tree\nphylo and evonet from ape\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-dplyr-verbs-in-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#the-dplyr-verbs-in-tidygraph",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.4.2 The dplyr verbs in tidygraph",
    "text": "9.4.2 The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dpylr verbs applied to tbl_graph object are applied to the active tibble\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly, .E() will give the edge data and .G() will give you the tbl_graph object itself"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#using-tbl_graph-to-build-tidy-graph-data-model",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#using-tbl_graph-to-build-tidy-graph-data-model",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.4.3 Using tbl_graph() to build tidy graph data model",
    "text": "9.4.3 Using tbl_graph() to build tidy graph data model\nIn this section, tbl_graph() of tinygraph package will be used to build a tidygraph’s network graph data.frame.\nA reference guide of tbl_graph can be found here.\n\n\nCode\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-output-tidygraphs-graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-output-tidygraphs-graph-object",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.4.4 Reviewing the output tidygraph’s graph object",
    "text": "9.4.4 Reviewing the output tidygraph’s graph object\n\n\nCode\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-output-tidygraphs-graph-object-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#reviewing-the-output-tidygraphs-graph-object-1",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.4.5 Reviewing the output tidygraph’s graph object",
    "text": "9.4.5 Reviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#changing-the-active-object",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#changing-the-active-object",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.4.6 Changing the active object",
    "text": "9.4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\n\n\nCode\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nMore information can be found in the reference guide of activate()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#plotting-a-basic-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#plotting-a-basic-network-graph",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.5.1 Plotting a basic network graph",
    "text": "9.5.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link(), and geom_node_point to plot a network graph by using GAStech_graph.\n\n\nCode\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#changing-the-default-network-graph-theme",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#changing-the-default-network-graph-theme",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.5.2 Changing the default network graph theme",
    "text": "9.5.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes.\n\n\nCode\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids and broder, changes the font to Arial Narrow (this can be overridden)\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#changing-the-coloring-of-the-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#changing-the-coloring-of-the-plot",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.5.3 Changing the coloring of the plot",
    "text": "9.5.3 Changing the coloring of the plot\nThe code theme_graph() makes it easy to change the coloring of the plot.\n\n\nCode\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-ggraphs-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-ggraphs-layouts",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.5.4 Working with ggraph’s layouts",
    "text": "9.5.4 Working with ggraph’s layouts\nggraph support many layout for standard use, they are: star, circle, nicely(default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph.\n\n\nCode\nlibrary(knitr)\ninclude_graphics(\"https://r4va.netlify.app/chap27/img/image4.jpg\")\n\n\n\n\n\n\n\n\n\n9.5.5 Fruchterman and Reingold Layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nCode\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nlayout argument is used to define the layout to be used"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#modifying-network-nodes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#modifying-network-nodes",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.5.6 Modifying network nodes",
    "text": "9.5.6 Modifying network nodes\nEach node will be colours based on their respective departments\n\n\nCode\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n9.5.7 Modifying Edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable\n\n\nCode\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But it can do more than that. In the example above, argument width is used to map the width of the line in proportion to the weight attribute and argument alpha is used to introduce opacity on the line"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-facet_edges",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-facet_edges",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.6.1 Working with facet_edges()",
    "text": "9.6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used.\n\n\nCode\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-facet_edges-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-facet_edges-1",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.6.2 Working with facet_edges()",
    "text": "9.6.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\n\nCode\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#a-framed-facet-graph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#a-framed-facet-graph",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.6.3 A Framed facet graph",
    "text": "9.6.3 A Framed facet graph\n\n\nCode\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-facet_nodes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-facet_nodes",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.6.4 Working with facet_nodes()",
    "text": "9.6.4 Working with facet_nodes()\nIn the code chunk below, facet_nodes() is used.\n\n\nCode\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#computing-centrality-indices",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#computing-centrality-indices",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.7.1 Computing centrality indices",
    "text": "9.7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nCode\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nmutate() of dplyr is used to perform the computation\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#visualising-network-metrics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#visualising-network-metrics",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.7.2 Visualising network metrics",
    "text": "9.7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nCode\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n9.7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nCode\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\n\nCode\nlibrary(ggforce)\nlibrary(concaveman)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(tidyverse)\nlibrary(igraph)\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#data-preparation",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.8.1 Data Preparation",
    "text": "9.8.1 Data Preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below:\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#plotting-the-first-interactive-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#plotting-the-first-interactive-network-graph",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.8.2 Plotting the first interactive network graph",
    "text": "9.8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nCode\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-layout",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.8.3 Working with layout",
    "text": "9.8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-visual-attributes---nodes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-visual-attributes---nodes",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.8.4 Working with visual attributes - Nodes",
    "text": "9.8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group\n\n\nCode\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-visual-attributes---edges",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#working-with-visual-attributes---edges",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.8.5 Working with visual Attributes - Edges",
    "text": "9.8.5 Working with visual Attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-On_Ex05.html#interactivity",
    "title": "Hands-On_Ex05 - Modelling, Visualising and Analysing Network Data with R",
    "section": "9.8.6 Interactivity",
    "text": "9.8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8 Part 1",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplry individually.\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\n\nCode\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\celinliaw\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nCode\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\n\nCode\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n\nCode\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\n\nCode\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\n\nCode\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\n\nCode\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\n\nCode\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\n\nCode\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01,  \n             fill_alpha = 0.1)\n\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\nIn the code chunk below, pretty data classification method is used.\nPretty breaks - give rounded nice numbers, default for continuous vairables\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"pretty\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt means that the breaks give pretty breaks, rounded nice numbers\n\nIn the code chunk below, kmeans data classification method is used.\nkmeans - breaks determined by k-means clustering\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-driven class breaks:\nThe breaks you see are not equally spaced (notice how 0.9 to 10.25 is a huge jump), because your data distribution is highly skewed.\nConcentration of lower values:\nMost planning areas have low dependency ratios (many polygons are in light shades).\nOutliers handled:\nThe highest class (10.25 to 19.00) handles the very few extreme high-dependency areas (e.g. the dark blue polygons).\nCluster boundaries not arbitrary:\nUnlike equal interval or quantile, these breaks reflect natural clusters found in your data using variance minimization.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\nIn the code below, 2 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 2)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code below, 6 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 6)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code below, 10 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 10)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code below, 20 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 20)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIt can be seen that the dependency ratio will be split into the number of classes that are specified and the difference between each dependency ratio is equal.\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\n\nCode\nsummary(mpsz_pop2020$DEPENDENCY)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7867  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to values argument of tm_scale_intervals() as shown in the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several tm_legend() options are provided to change the placement, format and appearance of the legend.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5,\n        values = \"brewer.greens\"),\n      fill.legend = tm_legend(\n        title = \"Dependency ratio\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\")\n\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\n\nCode\ntmap_style(\"white\")\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill().\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\n\nCode\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\n\nCode\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\n\nCode\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\n\nCode\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on Exercise 8 Part 1",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 8 Part 1",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplry individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "title": "Hands-on Exercise 8 Part 1",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\n\nCode\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\celinliaw\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nCode\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\n\nCode\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n\nCode\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\n\nCode\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\n\nCode\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\n\nCode\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8 Part 1",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\n\nCode\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\n\nCode\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01,  \n             fill_alpha = 0.1)\n\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\nIn the code chunk below, pretty data classification method is used.\nPretty breaks - give rounded nice numbers, default for continuous vairables\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"pretty\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt means that the breaks give pretty breaks, rounded nice numbers\n\nIn the code chunk below, kmeans data classification method is used.\nkmeans - breaks determined by k-means clustering\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-driven class breaks:\nThe breaks you see are not equally spaced (notice how 0.9 to 10.25 is a huge jump), because your data distribution is highly skewed.\nConcentration of lower values:\nMost planning areas have low dependency ratios (many polygons are in light shades).\nOutliers handled:\nThe highest class (10.25 to 19.00) handles the very few extreme high-dependency areas (e.g. the dark blue polygons).\nCluster boundaries not arbitrary:\nUnlike equal interval or quantile, these breaks reflect natural clusters found in your data using variance minimization.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\nIn the code below, 2 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 2)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code below, 6 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 6)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code below, 10 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 10)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code below, 20 classes are used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 20)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIt can be seen that the dependency ratio will be split into the number of classes that are specified and the difference between each dependency ratio is equal.\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\n\nCode\nsummary(mpsz_pop2020$DEPENDENCY)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7867  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to values argument of tm_scale_intervals() as shown in the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several tm_legend() options are provided to change the placement, format and appearance of the legend.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5,\n        values = \"brewer.greens\"),\n      fill.legend = tm_legend(\n        title = \"Dependency ratio\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\")\n\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\n\nCode\ntmap_style(\"white\")\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill().\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\n\nCode\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\n\nCode\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\n\nCode\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\n\nCode\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "title": "Hands-on Exercise 8 Part 1",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html",
    "title": "Hands-on Exercise 08 Part 3",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\n\nCode\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\n\nCode\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\n\n\n\n\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA\n\n\nCode\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"wp_functional\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\n\n\n\nCode\np2 &lt;- tm_shape(NGA_wp) + \n  tm_polygons(fill = \"total_wp\", \n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1, \n             fill_alpha = 1) + \n  tm_title(\"Distribution of total  water point by LGAs\")\n\n\n\n\nCode\ntmap_arrange(p2, p1, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\n\nCode\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\n\nCode\ntm_shape(NGA_wp) +\n  tm_polygons(\"pct_functional\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Rate map of functional water point by LGAs\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nCode\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\n\nCode\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nCode\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\n\nCode\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\n\nCode\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\n\nCode\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nCode\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nCode\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\n\nLet’s test the newly created function\n\n\nCode\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\n\nCode\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\n\n\nCode\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#overview",
    "title": "Hands-on Exercise 08 Part 3",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#getting-started",
    "title": "Hands-on Exercise 08 Part 3",
    "section": "",
    "text": "Code\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\n\nCode\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 08 Part 3",
    "section": "",
    "text": "Plot a choropleth map showing the distribution of non-function water point by LGA\n\n\nCode\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"wp_functional\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\n\n\n\nCode\np2 &lt;- tm_shape(NGA_wp) + \n  tm_polygons(fill = \"total_wp\", \n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1, \n             fill_alpha = 1) + \n  tm_title(\"Distribution of total  water point by LGAs\")\n\n\n\n\nCode\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 08 Part 3",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\n\nCode\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\n\nCode\ntm_shape(NGA_wp) +\n  tm_polygons(\"pct_functional\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Rate map of functional water point by LGAs\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part3.html#extreme-value-maps",
    "title": "Hands-on Exercise 08 Part 3",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nCode\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\n\nCode\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nCode\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\n\nCode\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\n\nCode\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\n\nCode\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nCode\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nCode\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\n\nLet’s test the newly created function\n\n\nCode\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\n\nCode\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\n\n\nCode\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024.\n\n\n\nAssuming the role of the graphical editor of the media company, you are tasked to prepare at most three data visualization for the article.\nTo accomplish the task, the data: Singapore Residents by Planning Area/Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore(DOS) is used.\n\n\n\nBased on these information, the following questions will be answered:\n\nWhat is the proportion of males and females in Singapore and is gender-balance consistent across Singapore?\nWhat is the age distribution of Singapore’s population in 2024 and is there a decrease in birth rates over the years?\nIs the current number of working adults enough to support the number of dependents in Singapore?"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#setting-the-scene",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#setting-the-scene",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "",
    "text": "A local online media company that publishes daily content on digital platforms is planning to release an article on demographic structures and distribution of Singapore in 2024."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#the-task",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#the-task",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "",
    "text": "Assuming the role of the graphical editor of the media company, you are tasked to prepare at most three data visualization for the article.\nTo accomplish the task, the data: Singapore Residents by Planning Area/Subzone, Single Year of Age and Sex, June 2024 dataset shared by Department of Statistics, Singapore(DOS) is used."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#breaking-down-the-question",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#breaking-down-the-question",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "",
    "text": "Based on these information, the following questions will be answered:\n\nWhat is the proportion of males and females in Singapore and is gender-balance consistent across Singapore?\nWhat is the age distribution of Singapore’s population in 2024 and is there a decrease in birth rates over the years?\nIs the current number of working adults enough to support the number of dependents in Singapore?"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#load-packages",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#load-packages",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nThe following packages are loaded using the pacman::p_load function:\n\ntidyverse: Core collection of R packages designed for data science\nggrepel: An R package to provide geoms for gg plot2 to repel overlapping text labels\nggthemes: An R package to provided extra themes, geoms and scales for ggplot 2\nhrbrthemes: an R packagae that provides typography-centric themes and theme componenets for ggplot2\npatchwork: to prepare composite figure created using ggplot2\ndplyr: An R package that provides a grammar of data manipulation, offering a set of functions for filtering, selecting, mutating, summarising and arranging data frames\n\n\npacman::p_load(tidyverse, ggrepel, \n               ggthemes,  hrbrthemes,\n               patchwork, dplyr)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#import-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#import-data",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "2.2 Import Data",
    "text": "2.2 Import Data\nThe data that has been used has been mentioned in Chapter 1.2 above. This dataset will be imported as resident_data.\n\nresident_data &lt;- read_csv(\"respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Check for duplicate entries\nThe data is being checked for any duplicate entries using any(duplicated()).\n\nany(duplicated(resident_data))\n\n[1] FALSE\n\n\nSince “FALSE” is returned, there are no duplicated entries\n\n\n2.3.2 Check for missing values\nThe colSums function is being used to check for missing values.\n\ncolSums(is.na(resident_data))\n\n  PA   SZ  Age  Sex  Pop Time \n   0    0    0    0    0    0 \n\n\nThere are no missing values in any of the rows.\n\n\n2.3.3 Filtering for relevant variables & renaming them\nThere are 60424 rows x 6 columns in the data, where the columns are labelled as:\n\nPA - Planning Area\nSZ - Subzone\nAge - From “0” to “89”, and those above 90 are labelled as “90_and_Over”\nSex - Males or Females\nPop - Resident Count (Has been rounded to the nearest 10)\nTime - Year (We will only be looking at 2024 data)\n\nA new object called resident_data_clean is created where it will rename PA, SZ and Pop for easy reading by using the rename() function.\nThose labelled as “90_and_Over” in the Age Column will be renamed as “90” using the ifelse() function for easier data plots.\nPopulation and age will then be categorised as numerical data by using the as.numeric function.\nFor the Age column, it is slightly special as levels = as.character function in R sorts alphabetically by default and “10” will come before “2”. By using this function, R will be forced to treat the ages in true numeric order when plotting or tabulating them. A new column, Age_numeric, was also created in the new object.\n\nresident_data_clean &lt;- resident_data %&gt;%\n  rename(\n    Planning_Area = PA,\n    Subzone = SZ,\n    Population = Pop\n  ) %&gt;%\n  # Convert Age to \"90+\" if it's \"90_and_Over\"\n  mutate(\n    Age = ifelse(Age == \"90_and_Over\", \"90\", Age),\n    Population = as.numeric(Population),\n    Age = factor(Age, levels = as.character(0:90)),\n    Age_numeric = as.numeric(as.character(Age))  \n  )\n\n\n\n2.3.4 Grouping them into Regions for Easy Visualization\nAs there are too many planning areas, to make things easier to visualize, the planning areas have been further categorised into 5 areas: North, North-East, East, West and Central. This was done by using the categories on the Urban Redevelopment Authority(URA) website:\n\nNorth: Central Water Catchment, Lim Chu Kang, Mandai, Sembawang, Simpang, Sungei Kadut, Woodlands, Yishun\nNorth-East: Ang Mo Kio, Hougang, Punggol, Sengkang, Serangoon, Seletar\nEast: Bedok, Changi, Changi Bay, Pasir Ris, Paya Lebar, Tampines\nWest: Boon Lay, Bukit Batok, Bukit Panjang, Choa Chu Kang, Clementi, Jurong East, Jurong West, Pioneer, Tengah, Tuas, Western Water Cachement\nCentral: Bishan, Bukit Merah, Bukit Timah, Central Area, Downtown Core, Marina East, Marina South, Museum, Newton, Novena, Orchard, Outram, River Valley, Rochor, Singapore River, Straits View, Tanglin\nAreas like North-Eastern Islands and Western islands were intentionally left out as they do not belong to any of the areas\n\nSteps:\nStep 1: A new list called region_map was created to categorise them into the 5 categories\n\n# 1. Step 1\nregion_map &lt;- list(\n  North = c(\n    \"Central Water Catchment\", \"Lim Chu Kang\", \"Mandai\",\n    \"Sembawang\", \"Simpang\", \"Sungei Kadut\", \"Woodlands\", \"Yishun\"\n  ),\n  `North-East` = c(\n    \"Ang Mo Kio\", \"Hougang\", \"Punggol\", \"Sengkang\", \n    \"Serangoon\", \"Seletar\"\n  ),\n  East = c(\n    \"Bedok\", \"Changi\", \"Changi Bay\", \n    \"Pasir Ris\", \"Paya Lebar\", \"Tampines\"\n  ),\n  West = c(\n    \"Boon Lay\", \"Bukit Batok\", \"Bukit Panjang\", \"Choa Chu Kang\",\n    \"Clementi\", \"Jurong East\", \"Jurong West\", \"Pioneer\", \n    \"Tengah\", \"Tuas\", \"Western Water Catchment\"\n  ),\n  Central = c(\n    \"Bishan\", \"Bukit Merah\", \"Bukit Timah\", \"Central Area\",\n    \"Downtown Core\", \"Marina East\", \"Marina South\", \"Museum\",\n    \"Newton\", \"Novena\", \"Orchard\", \"Outram\", \"River Valley\",\n    \"Rochor\", \"Singapore River\", \"Straits View\", \"Tanglin\"\n  )\n)\n\nStep 2: A new data object resident_regioned was then created with their region matched to them and those who were not found are removed using filter() function.\n\n# Step 2\nresident_regioned &lt;- resident_data_clean %&gt;%\n  mutate(\n    Region = case_when(\n      Planning_Area %in% region_map$North        ~ \"North\",\n      Planning_Area %in% region_map$`North-East` ~ \"North-East\",\n      Planning_Area %in% region_map$East         ~ \"East\",\n      Planning_Area %in% region_map$West         ~ \"West\",\n      Planning_Area %in% region_map$Central      ~ \"Central\",\n      TRUE                                       ~ NA_character_\n    )\n  ) %&gt;%\n  filter(!is.na(Region))\n\nThe data will then be grouped into their respective regions for the analysis.\n\n\n2.3.5 Preview Processed Data\n\nhead(resident_regioned)\n\n# A tibble: 6 × 8\n  Planning_Area Subzone          Age   Sex   Population  Time Age_numeric Region\n  &lt;chr&gt;         &lt;chr&gt;            &lt;fct&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt; \n1 Ang Mo Kio    Ang Mo Kio Town… 0     Males         10  2024           0 North…\n2 Ang Mo Kio    Ang Mo Kio Town… 0     Fema…         10  2024           0 North…\n3 Ang Mo Kio    Ang Mo Kio Town… 1     Males         10  2024           1 North…\n4 Ang Mo Kio    Ang Mo Kio Town… 1     Fema…         10  2024           1 North…\n5 Ang Mo Kio    Ang Mo Kio Town… 2     Males         10  2024           2 North…\n6 Ang Mo Kio    Ang Mo Kio Town… 2     Fema…         10  2024           2 North…\n\n\nNow that data wrangling is complete, 3 key visualizations will be performed on this data set."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#pie-chart-by-regions",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#pie-chart-by-regions",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "3.1 Pie Chart By Regions",
    "text": "3.1 Pie Chart By Regions\nFirst, groups were being created using groupby() to group them by regions and sex (Eg. East Males and East Females) so that the total population of each group can be found using sum(). After that, .groups = “drop” will remove the groups as ggplot doesn’t use groupings to plot and some functions that “mutate” may not turn out as expected.\nNext, ordered_levels was created to define the stacking order for the pie slices in an anti-clockwise direction.\nmutate() was used to add new columns to the pie_all_regions object.\nggplot() initializes a ggplot and the factors y = Population defines the height of each bar to be turned into pie slices and fill = RegionSex means the colour fill will be based on Sex.\ngeom_col draws bars with heights corresponding to population with width of 1 and white borders between pie slices.\ngeom_text was used to add percentage labels inside each pie slice with size of 3 and text colour black.\ncoord_polar(theta = “y”) converts stacked bar into a circular pie chart where the y-axis becomes the angle.\nlabs() help to add chart title and legend title.\nscale_fill_manual was used to set custom colours for each Region-Sex.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Summarise population by Region and Sex\npie_all_regions &lt;- resident_regioned %&gt;%\n  group_by(Region, Sex) %&gt;%\n  summarise(Population = sum(Population), .groups = \"drop\")\n\n\n# Define the correct stacking order for pie slices\nordered_levels &lt;- c(\n  \"Central.Males\", \"Central.Females\",\n  \"East.Males\", \"East.Females\",\n  \"North.Males\", \"North.Females\",\n  \"North-East.Males\", \"North-East.Females\",\n  \"West.Males\", \"West.Females\"\n)\n\n# Prepare the data\npie_all_regions &lt;- pie_all_regions %&gt;%\n  mutate(\n    RegionSex = factor(paste(Region, Sex, sep = \".\"), levels = ordered_levels),\n    label = paste0(round(Population / sum(Population) * 100, 1), \"%\")\n  )\n\n# Plot: simple, clean pie with percentages inside\nggplot(pie_all_regions, aes(x = \"\", y = Population, fill = RegionSex)) +\n  geom_col(width = 1, color = \"white\") +\n  geom_text(\n    aes(label = label),\n    position = position_stack(vjust = 0.5),\n    size = 3,\n    color = \"black\"\n  ) +\n  coord_polar(theta = \"y\") +\n  theme_void(base_size = 11) +\n  labs(\n    title = \"Population Composition by Region and Gender (2024)\",\n    fill = \"Region & Sex\"\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Central.Males\"     = \"#f4cccc\",\n      \"Central.Females\"   = \"#a94442\",\n      \"East.Males\"        = \"#d9ead3\",\n      \"East.Females\"      = \"#6aa84f\",\n      \"North.Males\"       = \"#fce5cd\",\n      \"North.Females\"     = \"#e69138\",\n      \"North-East.Males\"  = \"#d9d2e9\",\n      \"North-East.Females\"= \"#8e7cc3\",\n      \"West.Males\"        = \"#cfe2f3\",\n      \"West.Females\"      = \"#3c78d8\"\n    ),\n    breaks = rev(ordered_levels)\n  )\n\n\n\n\nObservations: From the pie chart, it can be seen that the proportion of males and females in each area is quite similar, only differing by 1-2%. However, it can be seen from the pie chart that the proportion of males are consistently lesser that the proportion of females in each area. We can then conclude that there are slightly less males than females in Singapore. Overall, gender balance is consistent across Singapore.\nAdditionally, the West and North-East Areas each made up 25% of the total population, accounting for half the population in Singapore while the North, Central and and East made up of the other half of Singapore’s population."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#age-sex-pyramid-by-regions",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#age-sex-pyramid-by-regions",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "3.2 Age-Sex Pyramid by Regions",
    "text": "3.2 Age-Sex Pyramid by Regions\nFor the age-sex pyramid, the data was then mutated using cut() and breaks() function to split them into Age categories: “0-9”, “10-19” and so on. In the cut() function, “right = FALSE” was used to exclude the upper bound of the bins so that they will consider 0-9 instead of 0-10 for each bin. A new column Age_bin was created.\n\nresident_regioned &lt;- resident_regioned %&gt;%\n  mutate(\n    Age_bin = cut(\n      Age_numeric,\n      breaks = c(seq(0, 90, by = 10), Inf),\n      labels = c(paste0(seq(0,80,by=10), \"-\", seq(9,89,by=10)), \"90 and Above\"),\n      right = FALSE\n    )\n  )\n\nA new data object pyramid_data was created to create the pyramid table. groupby() and summarise(Total = sum()) functions were used to group them by region(East, West etc), age group(Eg. 0-9, 10-19 etc) and sex(Males or females), before summing them up.\nValue = ifelse(Sex == “Males, -Total, Total”) was then used to flip males to negative values so they will be plotted to the left, while the female values remain as positive.\nLabel = format(Total, big.mark = “,”) is used to convert the numbers from 52300 to 52,300. These labels will be shown beside the bar graph.\nhjust = ifelse(Sex == “Males”, 1.1, -0.1) aligns the male label to the left of the graph and aligns the female label to the right of the graph.\n\npyramid_data &lt;- resident_regioned %&gt;%\n  group_by(Region, Age_bin, Sex) %&gt;%\n  summarise(Total = sum(Population), .groups = \"drop\") %&gt;%\n  mutate(\n    Value = ifelse(Sex == \"Males\", -Total, Total),\n    Label = format(Total, big.mark = \",\"),\n    hjust = ifelse(Sex == \"Males\", 1.1, -0.1)  # push left or right based on sex\n  )\n\nIn this section, individual plots for each region will be created and put together with patchwork.\nA reusable function called plot_region_pyramid will be created so that it can be called by its region name.\nggplot is then used next to plot the graph. aes( x = Value, y = Age_bin, fill = Sex) uses x-axis as Values so that Males are negative and Females are positive, y-axis is using the Age_bin which was created previously ranging from “0-9”, “10-19” etc and fill is coloured by the different Sex.\ngeom_col(width = 0.8) makes the width slightly smaller than 1 so that they do not touch.\ngeom_text(aes(label = Label, hjust = hjust), size = 2.8, color = “black”) is an aesthetic label that uses the pre-formatted functions in the code chunk before this.\nscale_x_continuous() helps to adjust the labels of the axis to follow pre-defined values mentioned in the code.\ncoord_cartesian() adjusts the actual values of the axis.\nscale_fill_manual sets the fill colour for males and females.\nlabs() add a title for each pane with the region name.\ntheme_minimal() uses the minimal theme.\n(p1 / p2 / p3 / p4 / p5) + plot_layout(guides = “collect”) helps to put the graphs together and show only 1 legend.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_region_pyramid &lt;- function(region_name) {\n  ggplot(\n    data = filter(pyramid_data, Region == region_name),\n    aes(x = Value, y = Age_bin, fill = Sex)\n  ) +\n    geom_col(width = 0.8) +\n    geom_text(aes(label = Label, hjust = hjust), size = 2.8, color = \"black\") +\n    scale_x_continuous(\n      breaks = c(-75000, -50000, -25000, 0, 25000, 50000, 75000),\n      labels = function(x) paste0(abs(x) / 1000, \"K\")\n    ) +\n    coord_cartesian(xlim = c(-85000, 85000)) +\n    scale_fill_manual(values = c(Males = \"#4472C4\", Females = \"#ED7D31\")) +\n    labs(\n      title = paste(\"Region:\", region_name),\n      x = \"Population\",\n      y = \"Age Group\"\n    ) +\n    theme_minimal(base_size = 11) +\n    theme(\n      legend.position = \"none\",\n      strip.text = element_text(face = \"bold\"),\n      axis.title.y = element_blank(),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.major.x = element_line(color = \"grey80\")\n    )\n}\n\n# Generate plots for each region\np1 &lt;- plot_region_pyramid(\"Central\")\np2 &lt;- plot_region_pyramid(\"East\")\np3 &lt;- plot_region_pyramid(\"North\")\np4 &lt;- plot_region_pyramid(\"North-East\")\np5 &lt;- plot_region_pyramid(\"West\")\n\n# Arrange using patchwork (2 columns)\n(p1 / p2 / p3 / p4 / p5) + plot_layout(guides = \"collect\")\n\n\n\n\nObservations: From the graphs, it can be seen that the population of Ages 30 to 69 are consistently larger than the population in the Age Range 0 to 29 and Ages 70 and above in most areas, resulting in a bulge in the middle of all the graphs in the five areas. This also shows that birth rates has decreased in the recent years.\nAdditionally, the population in the Age range of 0 to 29 has consistently more males than females in all areas except in the Central Area. However, those in the Age range 30 and above has more females than males in all areas with those aged 60 to 69 in the North area being the exception."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#bar-graph-of-dependency-ratio",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#bar-graph-of-dependency-ratio",
    "title": "Take-Home Exercise 1: Creating Data Visualization that is enlightening and truthful",
    "section": "3.3 Bar Graph of Dependency Ratio",
    "text": "3.3 Bar Graph of Dependency Ratio\nThe dependency ratio is a demographic measure that indicates the ratio of dependents (those typically not in the labour force) to the working-age population. Dependents are usually defined as those under 15 and above 65 years old.\nWith these information, the dependency ratio of the population in Singapore in the different regions will be calculated. This information will reflect the proportion of individuals who are likely to be economically dependent on others.\nadjusted_ageing_ratio_by_region is the new object created to add new custom age groups.\nmutate() is used to change the item to numeric so that &lt;= and &gt;= can be utilized to create the new custom Age_Group of 24 to 67 and 68 and above.\npivot_wider() is used to transform data from long format to wide format so that the ageing ratio can be calculated correctly.\nggplot() is used to plot the horizontal bar chart, using reorder() to reorder the x-axis so that the bars are sorted by ratio.\ngeom_col() is used to adjust the colour of the bars and geom_text() is used to add labels to the bars, using hjust to push the labels to the right of each bar.\ncoord_flip() is used to flip x and y axes and make it a horizontal bar chart.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nadjusted_ageing_ratio_by_region &lt;- resident_regioned %&gt;%\n  mutate(Age_numeric = as.numeric(as.character(Age))) %&gt;%\n  filter(!is.na(Age_numeric)) %&gt;%\n  mutate(Age_Group = case_when(\n    Age_numeric &lt; 15 | Age_numeric &gt;= 65 ~ \"&lt; 15 or &gt;=65\",\n    Age_numeric &gt;= 15 & Age_numeric &lt;= 64 ~ \"15-64\",\n    TRUE ~ \"Other\"\n  )) %&gt;%\n  filter(Age_Group != \"Other\") %&gt;%\n  group_by(Region, Age_Group) %&gt;%\n  summarise(Population = sum(Population), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = Age_Group, values_from = Population) %&gt;%\n  mutate(Adjusted_Ageing_Ratio = `&lt; 15 or &gt;=65` / `15-64`)\n\nggplot(adjusted_ageing_ratio_by_region, aes(x = reorder(Region, Adjusted_Ageing_Ratio), y = Adjusted_Ageing_Ratio)) +\n  geom_col(fill = \"#80CBC4\") +\n  geom_text(aes(label = round(Adjusted_Ageing_Ratio, 3)), hjust = -0.1) +\n  expand_limits(y = max(adjusted_ageing_ratio_by_region$Adjusted_Ageing_Ratio) * 1.1) +\n  labs(\n    title = \"Ratio of Dependents to Working Adults\",\n    x = \"Regions\",\n    y = \"Dependency Ratio\"\n  ) +\n  coord_flip() +\n  theme_minimal(base_size = 11) +\n  theme(axis.title.y = element_text(angle = 0, vjust = 0.5))\n\n\n\n\nObservations: From the bar graphs above, it can be seen that the dependency ratio (Population aged&lt;15 and &gt;65 / Population aged 15-65) ranges from 0.402 to 0.528. A ratio of 0.4 means that for every 2.5 working adults, there is 1 dependent, and a ratio of 0.528 means that for every 1.9 working adult, there is 1 dependent.\nThis average out to about 1 dependent to 2 working adults in Singapore, showing a healthy demographic structure."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "For this take-home exercise 2, Mini-Challenge 3 will be chosen and the visualisation will be done on this topic. The background of the mini challenge and the questions will be listed below. For this mini challenge, I will only be displaying and addressing Questions 2 and 3 below."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "title": "Take-Home_Ex02",
    "section": "Getting Started",
    "text": "Getting Started\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\n\nCode\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph,\n               SmartEDA, lubridate,\n               dplyr, igraph,\n               grid)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#import-knowledge-graph-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#import-knowledge-graph-data",
    "title": "Take-Home_Ex02",
    "section": "Import knowledge Graph Data",
    "text": "Import knowledge Graph Data\nFor this exercise, mc3.json file will be used. In the code chunk below, fromJSON() of jsonlite package is used to import mc3.json file into R and save the output object.\n\n\nCode\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#inspecting-knowledge-graph-structure",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#inspecting-knowledge-graph-structure",
    "title": "Take-Home_Ex02",
    "section": "Inspecting Knowledge graph structure",
    "text": "Inspecting Knowledge graph structure\nIn the code chunk below, glimpse() is used to reveal the structure of the mc3 knowledge graph.\n\n\nCode\nglimpse(MC3)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ..."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-Home_Ex02",
    "section": "Extracting the edges and nodes tables",
    "text": "Extracting the edges and nodes tables\nNext, as_tibble() of tibble package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes and mc3_edges respectively.\n\n\nCode\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#initial-eda",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#initial-eda",
    "title": "Take-Home_Ex02",
    "section": "Initial EDA",
    "text": "Initial EDA\nIn the code chunk below, ExpCatViz() of SmartEDA package is used to reveal the frequency distribution of all categorical fields in mc3_nodes tibble dataframe\n\n\nCode\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\nOn the other hand, code chunk below uses ExpCATViz() of SmartEDA package to reveal the frequency distribution of all categorical fields in mc3_edges tibble dataframe\n\n\nCode\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n\n[[1]]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-cleaning-and-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-cleaning-and-wrangling",
    "title": "Take-Home_Ex02",
    "section": "Data Cleaning and Wrangling",
    "text": "Data Cleaning and Wrangling\nThe code chunk below performs the following data cleaning tasks:\n\nconvert values in id field into character data type\nexclude records with id value\nexclude records with similar id values\nexclude thing_collected field\nsave the cleaned tibble dataframe into a new tibble datatable called mc_nodes_cleaned\n\n\n\nCode\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#cleaning-and-wrangling-edges",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#cleaning-and-wrangling-edges",
    "title": "Take-Home_Ex02",
    "section": "Cleaning and wrangling edges",
    "text": "Cleaning and wrangling edges\nNext, the code chunk will be used to:\n\nrename source and target fields to form_id and to_id respectively\nconvert values in from_id and to_id fields to character data type\nexclude values in from_id and to_id which is not found in the id field of mc3_nodes_cleaned\nexclude records whereby from_id and/or to_id values are missing\nsave the cleaned tibble dataframe and call it mc3_edges_cleaned\n\n\n\nCode\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source,\n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id),\n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id,\n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index.\n\n\nCode\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below will be used to join and convert from_id and to_id to integer indices. At the same time, we will drop rows with unmatched nodes.\n\n\nCode\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to))  \n\n\nNext, the code chunk below is used to subset nodes to only those referenced by edges\n\n\nCode\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe will then use th code chunk below to rebuild lookup from old index to new index\n\n\nCode\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table\n\n\nCode\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\nCode\nglimpse(mc3_edges_final)\n\n\nRows: 3,226\nColumns: 4\n$ from        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ to          &lt;int&gt; 1138, 357, 747, 895, 876, 888, 896, 145, 404, 876, 888, 92…\n$ is_inferred &lt;lgl&gt; TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, T…\n$ type        &lt;chr&gt; NA, \"sent\", NA, NA, NA, NA, NA, \"sent\", \"sent\", NA, NA, NA…"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q2-part-b",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q2-part-b",
    "title": "Take-Home_Ex02",
    "section": "Q2 Part B",
    "text": "Q2 Part B\nBased on the question 2b, I have categorised them into the 3 different Entity Subgroups: Person, Organisation and Vessel\n\nGroup by organisationGroup by PersonGroup by Vessels\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(wordcloud)\n\n# 1. Extract communication‐event nodes with their new_index and content\ncomm_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_index = new_index, content)\n\n# 2. Build a mapping from communication events to entities (Organization subtype)\nsend_map &lt;- mc3_edges_final %&gt;%\n  filter(type == \"sent\") %&gt;%\n  transmute(entity_index = from, event_index = to)\n\nrecv_map &lt;- mc3_edges_final %&gt;%\n  filter(type == \"received\") %&gt;%\n  transmute(event_index = from, entity_index = to)\n\nevent_to_entity &lt;- bind_rows(send_map, recv_map)\n\n# 3. Join event_to_entity with comm_nodes, then keep only Organization entities\ncomm_by_entity &lt;- event_to_entity %&gt;%\n  inner_join(comm_nodes, by = \"event_index\") %&gt;%\n  inner_join(\n    mc3_nodes_final %&gt;% \n      select(entity_index = new_index, sub_type, label),\n    by = \"entity_index\"\n  ) %&gt;%\n  filter(sub_type == \"Organization\") %&gt;%\n  select(organization = label, content)\n\n# 4. Collapse all texts per organization\norg_texts &lt;- comm_by_entity %&gt;%\n  group_by(organization) %&gt;%\n  summarize(text = paste(content, collapse = \" \"), .groups = \"drop\")\n\n# 5. Tokenize, remove stop‐words, and compute word frequencies per organization\ntidy_org_words &lt;- org_texts %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  anti_join(stop_words, by = \"word\") %&gt;%\n  count(organization, word, sort = TRUE)\n\n# 6. Plot one word cloud per organization\norg_list &lt;- unique(tidy_org_words$organization)\nn_orgs   &lt;- length(org_list)\nn_cols   &lt;- 3\nn_rows   &lt;- ceiling(n_orgs / n_cols)\n\npar(mfrow = c(n_rows, n_cols), mar = c(0, 0, 0, 0))\nfor (org in org_list) {\n  freq_tbl &lt;- tidy_org_words %&gt;% filter(organization == org)\n  if (nrow(freq_tbl) == 0) {\n    plot.new()\n    title(main = org)\n    next\n  }\n  v &lt;- setNames(freq_tbl$n, freq_tbl$word)\n  wordcloud(\n    words        = names(v),\n    freq         = as.numeric(v),\n    max.words    = 20,\n    scale        = c(3, 0.5),\n    random.order = FALSE\n  )\n  title(main = org, line = -1)\n}\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\nFor Organisation: It can be seen that Team Glitters does not have any pre-dominant topic area.\nOceanus City Council, Sailor Shift Team and Green Guardians seems to have common words like nemo, city, reef ,equipment and vessel, showing that they are more concerned about the environment.\nV. Miesel Shipping however, is more concerned about regulations as the most commonly used words are permit, operations and documentation.\n\n\n\n\nCode\n# (Assuming you already have mc3_nodes_final and mc3_edges_final loaded)\n\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(wordcloud)\n\n# 1. Extract communication‐event nodes with their new_index and content\ncomm_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_index = new_index, content)\n\n# 2. Build a mapping from communication events to entities\nsend_map &lt;- mc3_edges_final %&gt;%\n  filter(type == \"sent\") %&gt;%\n  transmute(entity_index = from, event_index = to)\n\nrecv_map &lt;- mc3_edges_final %&gt;%\n  filter(type == \"received\") %&gt;%\n  transmute(event_index = from, entity_index = to)\n\nevent_to_entity &lt;- bind_rows(send_map, recv_map)\n\n# 3. Join event_to_entity with comm_nodes, then keep only Person entities\ncomm_by_person &lt;- event_to_entity %&gt;%\n  inner_join(comm_nodes, by = \"event_index\") %&gt;%\n  inner_join(\n    mc3_nodes_final %&gt;% \n      select(entity_index = new_index, sub_type, label),\n    by = \"entity_index\"\n  ) %&gt;%\n  filter(sub_type == \"Person\") %&gt;%\n  select(person = label, content)\n\n# 4. Collapse all texts per person\nperson_texts &lt;- comm_by_person %&gt;%\n  group_by(person) %&gt;%\n  summarize(text = paste(content, collapse = \" \"), .groups = \"drop\")\n\n# 5. Tokenize, remove stop‐words, and compute word frequencies per person\ntidy_person_words &lt;- person_texts %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  anti_join(stop_words, by = \"word\") %&gt;%\n  count(person, word, sort = TRUE)\n\n# 6. Plot one word cloud per person\nperson_list &lt;- unique(tidy_person_words$person)\nn_persons   &lt;- length(person_list)\nn_cols      &lt;- 4\nn_rows      &lt;- ceiling(n_persons / n_cols)\n\npar(mfrow = c(n_rows, n_cols), mar = c(0, 0, 0, 0))\nfor (p in person_list) {\n  freq_tbl &lt;- tidy_person_words %&gt;% filter(person == p)\n  if (nrow(freq_tbl) == 0) {\n    plot.new()\n    title(main = p)\n    next\n  }\n  v &lt;- setNames(freq_tbl$n, freq_tbl$word)\n  wordcloud(\n    words        = names(v),\n    freq         = as.numeric(v),\n    max.words    = 10,\n    scale        = c(3, 0.5),\n    random.order = FALSE\n  )\n  title(main = p, line = -1)\n}\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\nFor Person Subgroups:\nTop 3 Commonly Used Words:\nMrs Money: Meeting, Nemo Reef, Intern\nThe Intern: Nemo Reef, Lookout, Money\nThe Lookout: Nemo Reef, Intern, tomorrow\nBoss: Nemo Reef, meeting, middleman\nThe Middleman: Nemo reef, boss, meeting\nThe Accountant: meeting, middleman, boss\nIt can be seen that these 6 people are in contact with each other as their most commonly used terms concern each other and usually revolves around Nemo Reef.\nLiam Thorne: Nemo Reef, council, report\nNadia Conti: Nemo Reef, documentation, meeting\nRodriguez: Nemo reef, davis, remora\nSamantha Blake: Nemo Reef, tomorrow, city council\nElise: Nemo Reef, tomorrow, meeting\nIt can also be seen that these group of people have common schedules like meeting, tomorrow and City Council, and they are also concerned about Nemo Reef.\nClepper Jensen: Miranda, equipment, environmental\nMiranda Jordan: Miranda, equipment, clepper Jensen\nDavis: Mako, security, equipment\nSam: birdwatching, lookout, reef\nMako: try, team, remora\nKelly: sam, kelly\nThese group of people here have different focus and do not have commonailities with the groups above.\n\n\n\n\nCode\n# 1. Extract communication‐event nodes with their new_index and content\ncomm_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_index = new_index, content)\n\n# 2. Build a mapping from communication events to entities (sender/receiver)\nsend_map &lt;- mc3_edges_final %&gt;%\n  filter(type == \"sent\") %&gt;%\n  transmute(entity_index = from, event_index = to)\n\nrecv_map &lt;- mc3_edges_final %&gt;%\n  filter(type == \"received\") %&gt;%\n  transmute(event_index = from, entity_index = to)\n\nevent_to_entity &lt;- bind_rows(send_map, recv_map)\n\n# 3. Join event_to_entity with comm_nodes, then keep only Vessel entities\ncomm_by_vessel &lt;- event_to_entity %&gt;%\n  inner_join(comm_nodes, by = \"event_index\") %&gt;%\n  inner_join(\n    mc3_nodes_final %&gt;%\n      select(entity_index = new_index, sub_type, label),\n    by = \"entity_index\"\n  ) %&gt;%\n  filter(sub_type == \"Vessel\") %&gt;%      # &lt;— change here\n  select(vessel = label, content)\n\n# 4. Collapse all texts per vessel\nvessel_texts &lt;- comm_by_vessel %&gt;%\n  group_by(vessel) %&gt;%\n  summarize(text = paste(content, collapse = \" \"), .groups = \"drop\")\n\n# 5. Tokenize, remove stop‐words, and compute word frequencies per vessel\ntidy_vessel_words &lt;- vessel_texts %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  anti_join(stop_words, by = \"word\") %&gt;%\n  count(vessel, word, sort = TRUE)\n\n# 6. Plot one word cloud per vessel\nvessel_list &lt;- unique(tidy_vessel_words$vessel)\nn_vess   &lt;- length(vessel_list)\nn_cols   &lt;- 4\nn_rows   &lt;- ceiling(n_vess / n_cols)\n\npar(mfrow = c(n_rows, n_cols), mar = c(0, 0, 0, 0))\nfor (ves in vessel_list) {\n  freq_tbl &lt;- tidy_vessel_words %&gt;% filter(vessel == ves)\n  if (nrow(freq_tbl) == 0) {\n    plot.new()\n    title(main = ves)\n    next\n  }\n  v &lt;- setNames(freq_tbl$n, freq_tbl$word)\n  wordcloud(\n    words        = names(v),\n    freq         = as.numeric(v),\n    max.words    = 20,\n    scale        = c(3, 0.5),\n    random.order = FALSE\n  )\n  title(main = ves, line = -1)\n}\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q3-part-a",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q3-part-a",
    "title": "Take-Home_Ex02",
    "section": "Q3 Part A",
    "text": "Q3 Part A\nThe pseudonyms used are:\n\nBoss\nThe Intern\nMrs Money\nThe Lookout\nThe Accountant\nThe Middleman"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q3-part-b",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q3-part-b",
    "title": "Take-Home_Ex02",
    "section": "Q3 Part B",
    "text": "Q3 Part B\nMy visualisations help to break down the communication on a daily basis and to draw the connections between the different people based on their communication groups.\nFrom the figures above, it can be seen that the Boss is mostly always on the receiving end of the communication, with the exception of Mako(Vessel). The ones who are in direct contact with Boss are Mrs Money, The Middleman, Rodriguez, Davis, Liam Thorne, The Accountant and Mako (Vessel).\nMrs Money, however, receives information mainly from The Intern.\nThe Lookout and The Intern, however, usually communicates in both directions, with The Intern usually on the receiving end of information.\nThe Accountant only got communicated with Boss on 11 October and he is often communicating with The Middleman.\nThe Lookout also sends informations to Sam.\nThere is a clear hierachy when sending information:\nLookout -&gt; Intern -&gt; Mrs Money/The Accountant/The Middleman -&gt; Boss\nLookout -&gt; Sam"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q3-part-c",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#q3-part-c",
    "title": "Take-Home_Ex02",
    "section": "Q3 Part C",
    "text": "Q3 Part C\nThese visualisations have confirmed my understanding that Boss is likely the leader of the group and the Vessel that is in contact with boss is likely Mako for illegal activities. The illegal activities should be taking place around Nemo Reef or meetings are held around Nemo Reef. The ones of higher positions are probably Mrs Money, The Middleman and The Accountant who reports directly to Boss.\nRodriguez, Liam Thorne and Davis seem to be involved directly with The Boss as well.\nStrangely, Nadia Conti seems to be at the receiving end of the communciation from Elise, Davis and Rodriguez and only replies to Liam Thorne. Nadia Conti is also in contact with several vessels.\nThe Intern and The Lookout seems to be of the same position in the syndicate, but The Intern is the only one who communicates with Mrs Money.\nThe Lookout seems to be reporting to Sam as well, as the communication is always in 1 direction.\nFrom all the previous analysis, I would like to conclude that Rodriguez and Davis are likely involved in the illegal activities as they are in direct contact with Boss. Sam is also likely involved as The Lookout reports to him frequently."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#getting-started",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "12.2 Getting Started",
    "text": "12.2 Getting Started\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "12.3 Geospatial Data Wrangling",
    "text": "12.3 Geospatial Data Wrangling\n\n12.3.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n12.3.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\n\nCode\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\n\nCode\nlist(sgpools)\n\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n12.3.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\n\nCode\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\n\nCode\nlist(sgpools_sf)\n\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "12.4 Drawing Proportional Symbol Map",
    "text": "12.4 Drawing Proportional Symbol Map\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\n\nCode\ntmap_mode(\"view\")\n\n\n\n12.4.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n           size = 1,\n           col = \"black\",\n           lwd = 1)\n\n\n\n\n\n\n\n\n12.4.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\n12.4.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\n\n12.4.4 I have twin brothers\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\n\nCode\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_Part2.html#reference",
    "title": "Hands-on Exercise 08 Part 2",
    "section": "12.5 Reference",
    "text": "12.5 Reference\n\n12.5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n12.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n12.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "",
    "text": "This storyboard will contain the tasks and questions from VAST Challenge and Mini Challenge 3. The visualisations will help to answer question 2 and 3 from MC3.\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jessen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#importing-libraries",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#importing-libraries",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "1. Importing Libraries",
    "text": "1. Importing Libraries\nAll these libraries will be used to build the Shiny website.\n\nshiny - Build and serve interactive web apps entirely in R\njsonlite - Read, write and manipulate JSON data quickly\ndplyr - Filter, mutate and summarise\npurr - For elegant list/vector iteration\nvisnetwork - create interactive network graphs\nDT - Render Interactive Data Tables\ntidygraph - Tidy-style verbs for graph data (nodes/edges) manipulation\nggraph - graphics plotting for network/graph objects\npatchwork - combine ggplots\ngrid - low level graphics system underpinning lattice, ggpllot\n\nlibrary(shiny)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(visNetwork)\nlibrary(DT)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(patchwork)\nlibrary(grid)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#creating-legend",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#creating-legend",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "2. Creating Legend",
    "text": "2. Creating Legend\nGive a legend to the different nodes\nlegend_cols &lt;- c(\n  Person        = \"#1b9e77\",\n  Vessel        = \"#d95f02\",\n  Organization  = \"#7570b3\",\n  Relationship  = \"#e7298a\",\n  Group         = \"#e6ab02\",\n  Location      = \"#66a61e\"\n)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#load-and-process-data",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#load-and-process-data",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "3. Load and Process Data",
    "text": "3. Load and Process Data\n\nread_json - reads the json files\nsimplifyVector = TRUE - ensure the nested arrays become data frames called graph$nodes and graph$edges\nevents_df - keeps only nodes where type == Event and timestamp is not missing\nfilter - to keep only dates from 2040-10-01 to 2040-10-15 (this is due to an error in the data where there is a year 2023, while all other data are from year 2040)\n\nnodes_all - used to create a new column category where type == Relationship and to label as “Relationship” and to only keep nodes that are in the legend category\nedges_all - rename source and target to “from” and “to” and adds a fixed “to” arrow direction for plotting the visnetwork\nA new column event_date is also created\n\ngraph &lt;- read_json(\"Data/MC3_graph.json\", simplifyVector = TRUE)\n\nevents_df &lt;- graph$nodes %&gt;%\n  filter(type == \"Event\", !is.na(timestamp)) %&gt;%\n  mutate(date = as.Date(timestamp)) %&gt;%\n  filter(date &gt;= as.Date(\"2040-10-01\"), date &lt;= as.Date(\"2040-10-15\"))\n\nmin_date &lt;- min(events_df$date)\nmax_date &lt;- max(events_df$date)\n\nnodes_all &lt;- graph$nodes %&gt;%\n  mutate(category = if_else(type == \"Relationship\", \"Relationship\", sub_type)) %&gt;%\n  filter(category %in% names(legend_cols)) %&gt;%\n  mutate(color = legend_cols[category])\n\nedges_all &lt;- graph$edges %&gt;%\n  transmute(from   = source,\n            to     = target,\n            type   = type,      # 'sent', 'received', etc.\n            arrows = \"to\") %&gt;%\n  left_join(events_df %&gt;% select(id, date), by = c(\"from\" = \"id\")) %&gt;%\n  rename(date_from = date) %&gt;%\n  left_join(events_df %&gt;% select(id, date), by = c(\"to\" = \"id\")) %&gt;%\n  rename(date_to   = date) %&gt;%\n  mutate(event_date = coalesce(date_from, date_to)) %&gt;%\n  select(-date_from, -date_to)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#ui",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#ui",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "4. UI",
    "text": "4. UI"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#server",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#server",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "5. Server",
    "text": "5. Server\n\nserver &lt;- function(input, output, session) {\n\n  #Additional Filtering of Edges and Nodes\n  edges_date &lt;- reactive({\n    edges_all %&gt;%\n      filter(is.na(event_date) |\n               (event_date &gt;= input$dateRange[1] &\n                  event_date &lt;= input$dateRange[2]))\n  })\n  \n  nodes_r &lt;- reactive({\n    req(input$classes)\n    ids &lt;- unique(c(edges_date()$from, edges_date()$to))\n    \n    n &lt;- nodes_all %&gt;%\n      filter(category %in% input$classes) %&gt;%\n      mutate(\n        color = if_else(category %in% names(legend_cols),\n                        legend_cols[category],\n                        NA_character_)\n      ) %&gt;%\n      filter(!is.na(color))  # remove anything that doesn't match the legend\n    \n    if (!isTRUE(input$isolates)) {\n      n &lt;- n %&gt;% filter(id %in% ids)\n    }\n    \n    n\n  })\n  \n  \n  edges_r &lt;- reactive({\n    ids &lt;- nodes_r()$id\n    edges_date() %&gt;% filter(from %in% ids & to %in% ids)\n  })\n  \n  output$net &lt;- renderVisNetwork({\n    net_nodes &lt;- nodes_r() %&gt;%\n      mutate(\n        category = if_else(category %in% names(legend_cols), category, NA_character_),\n        color = legend_cols[category]\n      ) %&gt;%\n      filter(!is.na(color)) %&gt;%   # removes nodes without defined colors\n      transmute(\n        id, label,\n        color.background = color,\n        color.border     = color,\n        color.highlight  = Map(function(c) list(background = c, border = \"#000000\"), color)\n      )\n    \n    net_edges &lt;- edges_r() %&gt;%\n      transmute(from, to, arrows = \"to\", label = type)\n    \n    if (nrow(net_nodes) == 0) return(visNetwork(data.frame(), data.frame()))\n    \n    visNetwork(net_nodes, net_edges) %&gt;%\n      visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n      visPhysics(stabilization = FALSE)\n  })\n  \n  \n  \n  # daily faceted plot (unchanged) \n  daily_plot &lt;- reactive({\n    \n    keep_cls &lt;- input$classes\n    if (length(keep_cls) &lt; 2) return(NULL)       # need at least two classes\n    \n    ## 1  communication edges inside the date window \n    e_full &lt;- edges_date() %&gt;%\n      filter(type %in% c(\"sent\",\"received\"),\n             !is.na(event_date))\n    if (nrow(e_full) == 0) return(NULL)\n    \n    ## 2  build sender → receiver pairs via the comm node \n    es &lt;- e_full %&gt;% filter(type == \"sent\")      %&gt;%\n      transmute(comm = to,   sender = from,  event_date)\n    er &lt;- e_full %&gt;% filter(type == \"received\")  %&gt;%\n      transmute(comm = from, receiver = to,  event_date)\n    \n    pv_edges &lt;- inner_join(es, er,\n                           by = c(\"comm\",\"event_date\")) %&gt;%\n      transmute(from = sender, to = receiver, event_date)\n    \n    if (nrow(pv_edges) == 0) return(NULL)\n    \n    ## 3  look up the categories of each endpoint \n    cat_lookup &lt;- nodes_all %&gt;% select(id, category)\n    \n    pv_edges &lt;- pv_edges %&gt;%\n      left_join(cat_lookup, by = c(\"from\" = \"id\")) %&gt;%\n      rename(cat_from = category) %&gt;%\n      left_join(cat_lookup, by = c(\"to\" = \"id\")) %&gt;%\n      rename(cat_to   = category) %&gt;%\n      filter(cat_from %in% keep_cls,                   # keep ONLY selected classes\n             cat_to   %in% keep_cls)\n    \n    if (nrow(pv_edges) == 0) return(NULL)\n    \n    ## 4  node table limited to kept classes \n    node_ids &lt;- unique(c(pv_edges$from, pv_edges$to))\n    pv_nodes &lt;- nodes_all %&gt;%\n      filter(id %in% node_ids, category %in% keep_cls) %&gt;%\n      select(id, label, category)\n    \n    ## 5  one facet per day \n    plots &lt;- lapply(sort(unique(pv_edges$event_date)), function(d){\n      \n      g &lt;- tbl_graph(\n        nodes = pv_nodes %&gt;% filter(id %in% c(\n          pv_edges$from[pv_edges$event_date == d],\n          pv_edges$to  [pv_edges$event_date == d] )),\n        edges = pv_edges %&gt;% filter(event_date == d),\n        directed = TRUE)\n      \n      ggraph(g, layout = \"fr\") +\n        geom_edge_link(\n          arrow       = grid::arrow(length = grid::unit(2, \"mm\")),\n          edge_colour = \"#666666\", edge_alpha = 0.5) +\n        geom_node_point(aes(color = category), size = 3) +\n        geom_node_text(aes(label = label), repel = TRUE, size = 3) +\n        scale_color_manual(values = legend_cols, breaks = names(legend_cols)) +\n        ggtitle(as.character(d)) +\n        theme_void() +\n        theme(legend.position = \"none\",\n              plot.title = element_text(size = 10, hjust = 0.5),\n              plot.margin     = margin(t = 10, r = 5, b = 20, l = 5))\n    })\n    \n    wrap_plots(plots, ncol = 2)\n  })\n  \n  output$dailyPlot &lt;- renderPlot(\n  height = function() {\n    ndays &lt;- length(unique(edges_date()$event_date))\n    row   &lt;- ceiling(ndays / 2)                # 2 panels per row (ncol = 2)\n    max(1, row) * 200                          # ~200 px per row\n  },\n  res = 96,                                    # keep your resolution\n  { daily_plot() }                             # &lt;- the existing expr\n)\n  # ---- tables --------------------------------------------------------\n  output$nodes_table &lt;- renderDT(\n    nodes_r()  %&gt;% select(id, label, category, color),\n    options = list(pageLength = 10), rownames = FALSE)\n  output$edges_table &lt;- renderDT(\n    edges_r() %&gt;% select(from, to, type, event_date),\n    options = list(pageLength = 10), rownames = FALSE)\n  \n\n  #  COMMUNICATION NETWORK  &lt;&lt;&lt;  ---------------\n  pv_pairs_full &lt;- reactive({\n    \n    e_full &lt;- edges_date() %&gt;%                 # already filtered by date\n      filter(type %in% c(\"sent\",\"received\"),   # keep comm edges\n             !is.na(event_date))\n    if (nrow(e_full) == 0)\n      return(tibble(from = character(), to = character()))\n    \n    es &lt;- e_full %&gt;% filter(type == \"sent\") %&gt;%\n      transmute(comm = to,   sender   = from)\n    er &lt;- e_full %&gt;% filter(type == \"received\") %&gt;%\n      transmute(comm = from, receiver = to)\n    \n    pairs &lt;- inner_join(es, er, by = \"comm\") %&gt;%  \n      transmute(from = sender, to = receiver)\n    \n    # attach categories for both ends\n    pairs &lt;- pairs %&gt;%\n      left_join(nodes_all %&gt;% select(id, category),\n                by = c(\"from\" = \"id\")) %&gt;%\n      rename(cat_from = category) %&gt;%\n      left_join(nodes_all %&gt;% select(id, category),\n                by = c(\"to\"   = \"id\")) %&gt;%\n      rename(cat_to   = category)\n    \n    # keep *any* combination picked in the sidebar\n    keep_cls &lt;- input$classes                  # Person / Vessel / Org / …\n    pairs %&gt;% filter(cat_from %in% keep_cls,\n                     cat_to   %in% keep_cls)\n  })\n  \n  \n  # (2) Aggregate counts \n  pv_edges_full &lt;- reactive({\n    pv_pairs_full() %&gt;%\n      count(from, to,  name = \"weight\")\n  })\n  \n  # (3) update dropdown choices whenever the data window changes \n  observe({\n    ids &lt;- unique(c(pv_edges_full()$from, pv_edges_full()$to))\n    labs &lt;- nodes_all %&gt;% filter(id %in% ids) %&gt;% arrange(label)\n    choices &lt;- setNames(c(\"All\", labs$id), c(\"All\", labs$label))\n    updateSelectInput(session, \"focus_id\", choices = choices)\n  })\n  \n  # (4) Filter by focus \n  pv_edges &lt;- reactive({\n    if (input$focus_id == \"All\") {\n      pv_edges_full()\n    } else {\n      pv_edges_full() %&gt;% filter(from == input$focus_id | to == input$focus_id)\n    }\n  })\n  \n  pv_nodes &lt;- reactive({\n    ids &lt;- unique(c(pv_edges()$from, pv_edges()$to))\n    nodes_all %&gt;% \n      filter(id %in% ids) %&gt;% \n      transmute(id, label, group = category, color)\n  })\n  \n  # (5) Render ----------------------------------------------------------\n  output$pv_net &lt;- renderVisNetwork({\n    \n    # 0. bail out early if nothing to show\n    req(nrow(pv_edges()) &gt; 0)\n    \n    # 1. node + edge tables \n    net_nodes &lt;- pv_nodes()\n    \n    net_edges &lt;- pv_edges() %&gt;% \n      transmute(\n        from, to,\n        label  = weight,                        # edge label\n        title  = paste(\"Count:\", weight),       # tooltip on hover\n        width  = 1 + weight,                    # &gt;&gt;&gt; thicker shaft\n        arrows = \"to\"                           # default arrow head\n      )\n    \n    # 2. build the visNetwork widget \n    visNetwork(net_nodes, net_edges) %&gt;%\n      visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n      visEdges(smooth = FALSE,\n               arrows = list(to = list(enabled = TRUE,\n                                       scaleFactor = 0.5))) %&gt;%  # global head size\n      visPhysics(stabilization = FALSE)\n  })\n}"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#ui-design",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#ui-design",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "4. UI Design",
    "text": "4. UI Design\n\nsidebarLayout - Used to create the controls for the display on the right\nselectInput - Used to select which Entities to display\nsliderInput - Used to change the date of event\ncheckboxInput - For removing isolated nodes\nmainPanel - Used to create the visualisation for the UI\ntabPanel - To create the different tabs to switch between visualisations\n\nui &lt;- fluidPage(\n  titlePanel(\"MC3 Entity & Relationship Network\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"classes\", \"Select Entity/Entities to Display:\",\n                  choices  = names(legend_cols),\n                  selected = c(\"Person\", \"Vessel\"),\n                  multiple = TRUE),\n      sliderInput(\"dateRange\", \"Event-date window:\",\n                  min = min_date, max = max_date,\n                  value = c(min_date, max_date),\n                  timeFormat = \"%Y-%m-%d\"),\n      checkboxInput(\"isolates\", \"Keep isolated nodes\", FALSE),\n      tags$hr(), tags$h5(\"Legend\"),\n      ## dynamic legend based on legend_cols -------------------------\n      tagList(lapply(names(legend_cols), function(cat) {\n        tags$div(style=\"display:flex; align-items:center; margin-bottom:4px;\",\n                 tags$span(style=sprintf(\n                   \"display:inline-block;width:14px;height:14px;border-radius:50%%;\\\n                    background:%s;margin-right:6px;\", legend_cols[cat])),\n                 tags$span(cat)\n        )\n      })),\n      width = 3\n    ),\n    mainPanel(\n      tabsetPanel(id = \"tabs\",\n                  \n                  tabPanel(\"Interactive Network\",\n                           visNetworkOutput(\"net\", height = \"800px\"), br(),\n                           tabsetPanel(type = \"tabs\",\n                                       tabPanel(\"Nodes\", DTOutput(\"nodes_table\")),\n                                       tabPanel(\"Edges\", DTOutput(\"edges_table\"))\n                           )\n                  ),\n                  tabPanel(\"Daily Communication Graph\",\n                           plotOutput(\"dailyPlot\")\n                  ),\n                  \n                  tabPanel(\"Frequency of Communication\",\n                           tags$h4(\"Additional visualisations are done below to further investigate the communication between\\nthe pseudonyms and real names.\"),\n                           tags$details(\n                             tags$summary(\"Code\"),\n                             p(\"Sender → receiver pairs are rebuilt from 'sent'/'received' edges,\",\n                               \"then aggregated; arrows show direction; edge width = count.\")\n                           ),\n                           selectInput(\"focus_id\", \"Select by id\",\n                                       choices = \"All\", selected = \"All\"),\n                           visNetworkOutput(\"pv_net\", height = \"700px\")\n                  )\n      )\n    )\n  )\n)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#final-visualisations",
    "href": "Take-Home_Ex/Take-Home_Ex03/Storyboard.html#final-visualisations",
    "title": "Take-Home_Ex03 - Storyboard",
    "section": "6. Final Visualisations",
    "text": "6. Final Visualisations\n\nCreating the Interactive Network\nThe user will be able to select the Entity/Entities and find out the relationship.\nThe use is also able to toggle the date to narrow down which dates they would like to view.\nThere is also a drop-down if they would like to Narrow down to specific person/relationship.\nThis network graph will help to figure out the relationship between each person/vessel/organisation/group.\n\n\n\nCreating the Daily Communication Graph\nThis daily communication graph allows the user to filter the communication for the day and who frequently communicates, narrowing down the groups of people that are associated with each other.\n\n\n\nCreating the Frequency of Communication Graph\nThe thickness of the arrows show the frequency of the communication. The thicker the arrows, the more frequent the communication."
  }
]